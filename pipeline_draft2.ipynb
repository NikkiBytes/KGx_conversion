{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### **KGX Format Overview**\n",
    "\n",
    "KGX (Knowledge Graph Exchange) is a Python library and set of utilities for exchanging knowledge graphs (KGs) that conform to the Biolink Model. It provides tools for converting, validating, and exchanging knowledge graphs in various formats, including JSON, TSV, RDF, and Neo4j.\n",
    "\n",
    "#### **Core Features**\n",
    "- **Property Graph Representation**: Internally represented as a `networkx.MultiDiGraph`.\n",
    "- **Biolink Model Compliance**: Ensures nodes and edges conform to the Biolink Model, including valid categories, predicates, and properties.\n",
    "- **Supported Formats**:\n",
    "  - RDF (read/write) and SPARQL endpoints (read).\n",
    "  - Neo4j endpoints (read) or dumps (write).\n",
    "  - CSV/TSV and JSON.\n",
    "  - Reasoner Standard API format.\n",
    "  - OBOGraph JSON format.\n",
    "\n",
    "\n",
    "### **KGX Format Details**\n",
    "\n",
    "#### **Node Record**\n",
    "Each node in a KGX graph is represented as a **Node Record** with the following elements:\n",
    "\n",
    "- **Required Elements**:\n",
    "  - `id`: A CURIE uniquely identifying the node.\n",
    "  - `category`: A list of Biolink Model categories describing the node.\n",
    "\n",
    "- **Optional Elements**:\n",
    "  - **Biolink Model Properties**: e.g., `name`, `description`, `xref`, `provided_by`.\n",
    "  - **Non-Biolink Properties**: Custom properties not defined in the Biolink Model.\n",
    "\n",
    "#### **Edge Record**\n",
    "Each edge in a KGX graph is represented as an **Edge Record** with the following elements:\n",
    "\n",
    "- **Required Elements**:\n",
    "  - `subject`: The source node's `id`.\n",
    "  - `predicate`: The relationship type (from the Biolink `related_to` hierarchy).\n",
    "  - `object`: The target node's `id`.\n",
    "\n",
    "- **Optional Elements**:\n",
    "  - **Biolink Model Properties**: e.g., `category`, `publications`.\n",
    "  - **Edge Provenance**: e.g., `primary_knowledge_source`, `supporting_data_source`.\n",
    "\n",
    "\n",
    "### **KGX Format Examples**\n",
    "\n",
    "#### **KGX JSON Format**\n",
    "The JSON format represents the graph as a dictionary with `nodes` and `edges` arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': [{'id': 'HGNC:11603',\n",
       "   'name': 'TBX4',\n",
       "   'category': ['biolink:Gene'],\n",
       "   'provided_by': ['MonarchArchive:gwascatalog']},\n",
       "  {'id': 'MONDO:0005002',\n",
       "   'name': 'chronic obstructive pulmonary disease',\n",
       "   'category': ['biolink:Disease'],\n",
       "   'provided_by': ['MonarchArchive:gwascatalog']}],\n",
       " 'edges': [{'id': 'urn:uuid:5b06e86f-d768-4cd9-ac27-abe31e95ab1e',\n",
       "   'subject': 'HGNC:11603',\n",
       "   'predicate': 'biolink:contributes_to',\n",
       "   'object': 'MONDO:0005002',\n",
       "   'relation': 'RO:0003304',\n",
       "   'category': ['biolink:GeneToDiseaseAssociation'],\n",
       "   'primary_knowledge_source': ['MonarchArchive:gwascatalog'],\n",
       "   'publications': ['PMID:26634245', 'PMID:26634244']}]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"nodes\": [\n",
    "    {\n",
    "      \"id\": \"HGNC:11603\",\n",
    "      \"name\": \"TBX4\",\n",
    "      \"category\": [\"biolink:Gene\"],\n",
    "      \"provided_by\": [\"MonarchArchive:gwascatalog\"]\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"MONDO:0005002\",\n",
    "      \"name\": \"chronic obstructive pulmonary disease\",\n",
    "      \"category\": [\"biolink:Disease\"],\n",
    "      \"provided_by\": [\"MonarchArchive:gwascatalog\"]\n",
    "    }\n",
    "  ],\n",
    "  \"edges\": [\n",
    "    {\n",
    "      \"id\": \"urn:uuid:5b06e86f-d768-4cd9-ac27-abe31e95ab1e\",\n",
    "      \"subject\": \"HGNC:11603\",\n",
    "      \"predicate\": \"biolink:contributes_to\",\n",
    "      \"object\": \"MONDO:0005002\",\n",
    "      \"relation\": \"RO:0003304\",\n",
    "      \"category\": [\"biolink:GeneToDiseaseAssociation\"],\n",
    "      \"primary_knowledge_source\": [\"MonarchArchive:gwascatalog\"],\n",
    "      \"publications\": [\"PMID:26634245\", \"PMID:26634244\"]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **KGX TSV Format**\n",
    "The TSV format separates nodes and edges into two files: `nodes.tsv` and `edges.tsv`.\n",
    "\n",
    "**nodes.tsv**:\n",
    "| id            | category                                                                 | name                                  | provided_by               |\n",
    "|---------------|--------------------------------------------------------------------------|---------------------------------------|---------------------------|\n",
    "| HGNC:11603    | biolink:NamedThing\\|biolink:BiologicalEntity\\|biolink:Gene               | TBX4                                  | MonarchArchive:gwascatalog |\n",
    "| MONDO:0005002 | biolink:NamedThing\\|biolink:BiologicalEntity\\|biolink:DiseaseOrPhenotypicFeature\\|biolink:Disease | chronic obstructive pulmonary disease | MonarchArchive:gwascatalog |\n",
    "\n",
    "**edges.tsv**:\n",
    "| id                                    | subject     | predicate                  | object         | relation   | primary_knowledge_source | category                        | publications               |\n",
    "|---------------------------------------|-------------|----------------------------|----------------|------------|---------------------------|---------------------------------|---------------------------|\n",
    "| urn:uuid:5b06e86f-d768-4cd9-ac27-abe31e95ab1e | HGNC:11603  | biolink:contributes_to    | MONDO:0005002  | RO:0003304 | MonarchArchive:gwascatalog | biolink:GeneToDiseaseAssociation | PMID:26634245\\|PMID:26634244 |\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "- **Validation**: KGX ensures that nodes and edges conform to the Biolink Model.\n",
    "- **Flexibility**: Supports both Biolink and non-Biolink properties.\n",
    "- **Interoperability**: Facilitates exchange between different graph systems and formats.\n",
    "\n",
    "Documntation: [KGX documentation](https://github.com/biolink/kgx).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************** Draft ********************** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KGX Format Pipeline Process**\n",
    "\n",
    "This pipeline processes data from a SmartAPI source, maps it to the Biolink Model, and formats it into a KGX-compatible JSON file. Below is a step-by-step description of the process:\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Query SmartAPI Metadata**\n",
    "- **Input**: SmartAPI ID (`api_id`) and API name (`api_name`).\n",
    "- **Process**:\n",
    "  - Construct a SmartAPI query URL using the `api_id`.\n",
    "  - Send a GET request to retrieve metadata about the API.\n",
    "- **Output**: Metadata in JSON format (`data`).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Create Biolink Mappings**\n",
    "- **Input**: SmartAPI metadata (`data`).\n",
    "- **Process**:\n",
    "  - Extract nodes and edges from the metadata.\n",
    "  - Map entities (nodes) and relationships (edges) to Biolink Model URIs using the Biolink Model Toolkit (BMT).\n",
    "  - Deduplicate and structure the mappings.\n",
    "- **Output**: `node_mappings` and `edge_mappings`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Query BioThings API**\n",
    "- **Input**: `node_mappings`, `edge_mappings`, and a BioThings API client.\n",
    "- **Process**:\n",
    "  - Query the BioThings API for all data (`__all__`).\n",
    "  - Extract node and edge information based on the Biolink mappings.\n",
    "  - Format nodes and edges into dictionaries.\n",
    "- **Output**: Lists of `nodes` and `edges`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Format Data into KGX**\n",
    "- **Input**: `nodes` and `edges`.\n",
    "- **Process**:\n",
    "  - Combine nodes and edges into a KGX-compatible dictionary.\n",
    "  - Deduplicate nodes and edges.\n",
    "- **Output**: A KGX dictionary (`kgx_dict`).\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Write KGX to JSON | TSV**\n",
    "- **Input**: `kgx_dict`.\n",
    "- **Process**:\n",
    "  - Serialize the KGX dictionary into a JSON file.\n",
    "  - Save the file locally (e.g., \n",
    "\n",
    "raresource_kgx_test2.json\n",
    "\n",
    ").\n",
    "- **Output**: A JSON file in KGX format.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************** Draft Code ********************** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get the ID prefix priority list for biolink:Disease\n",
    "element = BMT.get_element_by_mapping(\"orphanet:39041\")\n",
    "print(element)\n",
    "# preferred_prefixes = element\n",
    "\n",
    "# print(preferred_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NCBIGene:100'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'disease_prefix': get_preferred_prefix('orphanet:39041')  # ‚Üí 'MONDO'\n",
    "# get_preferred_id('NCBIGene:100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMT.get_element_by_mapping(\"orphanet:277\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BMT.is_translator_canonical_predicate(\"biolink:gene_associated_with_condition\")\n",
    "BMT.is_symmetric(\"biolink:gene_associated_with_condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_norm = f\"https://nodenorm.ci.transltr.io/1.5/get_normalized_nodes?curie={CURIE}&conflate=false&drug_chemical_conflate=false&description=false&individual_types=false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preferred_id(curie):\n",
    "    url = f\"https://nodenorm.ci.transltr.io/1.5/get_normalized_nodes?curie={curie}&conflate=false&drug_chemical_conflate=false&description=false&individual_types=false\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        norm = data.get(curie)\n",
    "        if norm and 'id' in norm:\n",
    "            identifier = norm['id']['identifier']\n",
    "            # return identifier.split(\":\")[0]  # e.g., MONDO\n",
    "            return identifier\n",
    "    return curie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************** Original Code ********************** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3018815242.py, line 101)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[56], line 101\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"ref_url\": y_[0][0] for y_ in ref_url,\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_biothings_api(node_mappings, edge_mappings, bt_data): # abstract out for one record\n",
    "    # Iterate through BioThings API data    \n",
    "    # Extract node data based on Biolink mappings\n",
    "    # print('[INFO] BT data:', bt_data)\n",
    "\n",
    "    for pred_uri, value in edge_mappings.items():\n",
    "        # print(f\"[INFO] Predicate URI: {pred_uri} | Value: {value}\")\n",
    "    #     print(value.keys())\n",
    "        s_uri = value[\"subject\"]\n",
    "        o_uri = value[\"object\"]\n",
    "        # print(f\"[INFO] Subject URI: {s_uri} | Object URI: {o_uri}\")\n",
    "        s_data = node_mappings[s_uri]\n",
    "        o_data = node_mappings[o_uri]\n",
    "        # print(f\"[INFO] Subject data: {s_data} | Object data: {o_data}\")\n",
    "        s_identifier_key = s_data['identifier']\n",
    "        o_identifier_key = o_data['identifier']\n",
    "        s_prefix = s_data['prefix']\n",
    "        o_prefix = o_data['prefix']\n",
    "        s_category = [key for key,value in node_mappings.items() if value['prefix'] == s_prefix]\n",
    "        o_category = [key for key,value in node_mappings.items() if value['prefix'] == o_prefix]\n",
    "    #     s_prefix = s_data['prefix']\n",
    "    #     s_category\n",
    "\n",
    "        # try:\n",
    "        s_identifiers = get_nested_value(bt_data,s_identifier_key)\n",
    "        o_identifiers = get_nested_value(bt_data,o_identifier_key)\n",
    "        if o_identifiers is None or s_identifiers is None:\n",
    "            # print(f\"[INFO] Found subject identifiers: {s_identifiers} key: {s_identifier_key} \\n\")\n",
    "            # print(f\"[INFO] Found object identifiers:{o_identifiers} key: {o_identifier_key}\")\n",
    "            continue\n",
    "        # print(f\"[INFO] Found subject identifiers: {s_identifiers} key: {s_identifier_key} \\n\")\n",
    "        # ******************************************\n",
    "        # Create Nodes\n",
    "        for s_ in s_identifiers:\n",
    "            s_node_id =  f\"{s_prefix}:{s_[0]}\"\n",
    "            s_node_name = s_[1] \n",
    "            # s_node_norm_id = get_preferred_id(s_node_id)  # Use '=' for assignment\n",
    "            # print(f\"[INFO] {s_node_id} | {s_node_name}\")\n",
    "            if s_node_id not in nodes:\n",
    "                nodes[s_node_id] = {\n",
    "                    \"id\": s_node_id,\n",
    "                    \"name\": s_node_name,\n",
    "                    \"category\": s_category\n",
    "                    # \"provided_by\": [node_mappings[s_uri]['provided_by']]\n",
    "                }\n",
    "                for prop_key, prop_value in node_mappings[s_uri]['properties'].items():\n",
    "                    # print(prop_key)\n",
    "                    if \".\" in prop_value:\n",
    "                        pass\n",
    "                    else:\n",
    "                        if prop_key in prop_value:\n",
    "                            v_ = bt_data[prop_key]\n",
    "                            nodes[s_node_id][prop_key] = v_\n",
    "                        \n",
    "                # pprint.pprint(nodes[s_node_id])\n",
    "            for o_ in o_identifiers:\n",
    "                o_node_id =  f\"{o_prefix}:{o_[0]}\"\n",
    "                o_node_name = o_[1]\n",
    "                o_node_norm_id = get_preferred_id(o_node_id)\n",
    "                # print(f\"[INFO] {o_node_id} | {o_node_name}\")\n",
    "                if o_node_id not in nodes:\n",
    "                    nodes[o_node_id] = {\n",
    "                        \"id\": o_node_id,\n",
    "                        \"name\": o_node_name,\n",
    "                        \"category\": o_category\n",
    "                        # \"provided_by\": [node_mappings[o_uri]['provided_by']]\n",
    "                    }\n",
    "                    for prop_key, prop_value in node_mappings[o_uri]['properties'].items():\n",
    "                        if \".\" in prop_value:                            \n",
    "                            nested_ids = get_nested_value(bt_data, prop_value)\n",
    "                            if nested_ids is not None:\n",
    "                                for nest_id in nested_ids:\n",
    "                                    nodes[o_node_id][prop_key.split(\".\")[-1]] = nest_id[0]\n",
    "                        else:\n",
    "                            if prop_key in bt_data:\n",
    "                                v_ = bt_data[prop_key]\n",
    "                                nodes[o_node_id][prop_key] = v_\n",
    "                # pprint.pprint(nodes[o_node_id])\n",
    "                # ******************************************\n",
    "                # Create Edges\n",
    "                is_canonical = BMT.is_translator_canonical_predicate(pred_uri)\n",
    "                is_symmetric = BMT.is_symmetric(pred_uri)\n",
    "\n",
    "                if is_canonical:\n",
    "                    print(f\"[INFO] Predicate is canonical: {pred_uri} | {is_canonical}\")\n",
    "                    # if is_symmetric:\n",
    "                    #     print(f\"[INFO] {pred_uri} is also symmetric (this is unusual for canonical predicates).\")\n",
    "                    # else:\n",
    "                    #     print(f\"[INFO] {pred_uri} is NOT symmetric (expected for canonical predicates).\")\n",
    "                    rel = f\"{s_node_id}-{pred_uri}-{o_node_id}\"\n",
    "                    if rel not in edges:\n",
    "                        ref_url = get_nested_value(bt_data, edge_mappings[pred_uri]['properties']['ref_url'])\n",
    "                        print(ref_url)\n",
    "                        edges[rel] = {\n",
    "                            \"subject\": s_node_id,\n",
    "                            \"predicate\": pred_uri,\n",
    "                            \"object\": o_node_id,\n",
    "                            \"knowledge_level\": edge_mappings[pred_uri]['knowledge_level'],\n",
    "                            \"agent_type\": edge_mappings[pred_uri]['agent_type'],\n",
    "                            \"primary_knowledge_source\": edge_mappings[pred_uri]['primary_knowledge_source'],\n",
    "                            \"ref_url\": y_[0][0] for y_ in ref_url,\n",
    "                            \n",
    "                        }\n",
    "\n",
    "        # except Exception as error:\n",
    "        #     print(f\"\\n[INFO] ERROR: {error}\\n\")\n",
    "        #     pass\n",
    "\n",
    "    return nodes,edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_nested_value(data, key_path):\n",
    "# #     \"\"\"\n",
    "# #     # Biothings Util function? \n",
    "# #     Retrieve a value from a nested dictionary using a dot-separated key path.\n",
    "# #     Handles lists if encountered during traversal.\n",
    "# #     Example: key_path = \"raresource.disease.orphanet\" will return the value of\n",
    "# #     data[\"raresource\"][\"disease\"][0][\"orphanet\"] if \"disease\" is a list.\n",
    "# #     \"\"\"\n",
    "\n",
    "# #     keys = key_path.split(\".\")  # Split the key path into individual keys\n",
    "# #     temp_data=data.copy() # for reference\n",
    "# #     loop_ct=0\n",
    "\n",
    "# #     # print('here')\n",
    "# #     for i, key in enumerate(keys):\n",
    "# #         # print(key)\n",
    "# #         # print(\"in loop...\")\n",
    "# #         loop_ct+=1\n",
    "# #         is_final_key = (i == len(keys) - 1)\n",
    "# #         # data=data[key]\n",
    "# #         # print(key, type(data), loop_ct)\n",
    "# #         # print(f\"Starting data: {type(data)} {type(temp_data)} {key}\" )\n",
    "# #         # *********************************************************************************************************\n",
    "# #         if isinstance(data, dict) and key in data:\n",
    "# #             # print(f\"[INFO] Dictionary loop on key: {key}\")\n",
    "# #             if key in data:\n",
    "# #                 temp_data = data[key]\n",
    "# #                 if isinstance(temp_data, str): # found a string ID\n",
    "# #                     id_ = temp_data\n",
    "# #                     # print(f\"[INFO] Inside string ID instance: {key}, {id_}\")\n",
    "# #                     # print(data.keys())\n",
    "# #                     for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]: # **MAKE REGEX** (drug_name, etc...)\n",
    "# #                         if search_key in data:\n",
    "# #                             name = data[search_key]\n",
    "# #                             break\n",
    "# #                         else:\n",
    "# #                             name = None\n",
    "# #                     return [(id_, name)]\n",
    "# #                 data = data[key]\n",
    "# #             else:\n",
    "# #                 # print(f\"Key {key} not found in dictionary.\")\n",
    "# #                 return None\n",
    "# #             # print(f\"Ending data: {type(data)} {type(temp_data)} {key}\\n\" )\n",
    "# #         # *********************************************\n",
    "# #         elif isinstance(data, list):\n",
    "# #             # print(f\"[INFO] List loop on key: {key}\")\n",
    "# #             # If the current data is a list, assume we want the first element\n",
    "# #             if len(data) > 0:\n",
    "# #                 # print(data)\n",
    "# #                 if is_final_key:\n",
    "# #                     # print(\"[INFO] is final key\", key)\n",
    "# #                     id_list = []\n",
    "# #                     for data_dict in data:\n",
    "# #                         if key in data_dict:\n",
    "# #                             # print(\"[INFO] found key \", key)\n",
    "# #                             id_ = data_dict[key]\n",
    "# #                             # print(\"\\n\", id_, key)\n",
    "# #                             # pprint.pprint(data_dict)\n",
    "# #                             name = None\n",
    "# #                             for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\",\"drug_name\"]: # **MAKE REGEX** (drug_name, etc...)\n",
    "# #                                 if search_key in data_dict:\n",
    "# #                                     name = data_dict[search_key]\n",
    "# #                                     break\n",
    "# #                             id_list.append((id_, name))\n",
    "# #                         else:\n",
    "# #                             return None # key not found -- this does happen , i.e orphanet in raresource\n",
    "# #                     # print(f\"Returning from list: {id_list}\")\n",
    "# #                     return id_list\n",
    "# #                 # temp_data = temp_data[key]\n",
    "# #                 # data = data[key]\n",
    "# #             else:\n",
    "# #                 print(\"Empty list encountered.\")\n",
    "# #                 return None\n",
    "# #         # *********************************************\n",
    "# #         elif isinstance(data, str):\n",
    "# #             print(f\"[INFO] String loop on key: {key}\")\n",
    "\n",
    "# #             # If this is the final key, check for specific keys in the list element\n",
    "# #             if is_final_key and isinstance(temp_data, dict) and key in temp_data:\n",
    "# #                 for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]: # **MAKE REGEX** (drug_name, etc...)\n",
    "# #                     if search_key in temp_data:\n",
    "# #                         id_ = data\n",
    "# #                         name = temp_data[search_key]\n",
    "# #                         # print(f\"Returning from list: {id_} | {name}\")\n",
    "# #                         return [(id_, name)]\n",
    "# #             return(data, None)\n",
    "# #         # *********************************************\n",
    "# #         else:\n",
    "# #             ...\n",
    "# #         # *********************************************************************************************************\n",
    "        \n",
    "\n",
    "# #     return None\n",
    "\n",
    "# def get_nested_value(data, key_path):\n",
    "#     \"\"\"\n",
    "#     Retrieve a value from a nested dictionary using a dot-separated key path.\n",
    "#     Handles lists if encountered during traversal.\n",
    "#     Example: key_path = \"raresource.disease.orphanet\" will return the value of\n",
    "#     data[\"raresource\"][\"disease\"][0][\"orphanet\"] if \"disease\" is a list.\n",
    "#     \"\"\"\n",
    "\n",
    "#     keys = key_path.split(\".\")  # Split the key path into individual keys\n",
    "#     temp_data = data.copy()  # For reference\n",
    "#     loop_ct = 0\n",
    "\n",
    "#     for i, key in enumerate(keys):\n",
    "#         loop_ct += 1\n",
    "#         is_final_key = (i == len(keys) - 1)\n",
    "\n",
    "#         if isinstance(data, dict) and key in data:\n",
    "#             temp_data = data[key]\n",
    "#             if isinstance(temp_data, str):  # Found a string ID\n",
    "#                 id_ = temp_data\n",
    "#                 for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]:\n",
    "#                     if search_key in data:\n",
    "#                         name = data[search_key]\n",
    "#                         break\n",
    "#                     else:\n",
    "#                         name = None\n",
    "#                 # Return the entire dictionary at this level\n",
    "#                 return {\"id\": id_, \"name\": name, \"all_keys\": data}\n",
    "#             data = data[key]\n",
    "\n",
    "#         elif isinstance(data, list):\n",
    "#             if len(data) > 0:\n",
    "#                 if is_final_key:\n",
    "#                     id_list = []\n",
    "#                     for data_dict in data:\n",
    "#                         if key in data_dict:\n",
    "#                             id_ = data_dict[key]\n",
    "#                             name = None\n",
    "#                             for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]:\n",
    "#                                 if search_key in data_dict:\n",
    "#                                     name = data_dict[search_key]\n",
    "#                                     break\n",
    "#                             # Return the entire dictionary at this level\n",
    "#                             id_list.append({\"id\": id_, \"name\": name, \"all_keys\": data_dict})\n",
    "#                         else:\n",
    "#                             return None  # Key not found\n",
    "#                     return id_list\n",
    "#             else:\n",
    "#                 print(\"Empty list encountered.\")\n",
    "#                 return None\n",
    "\n",
    "#         elif isinstance(data, str):\n",
    "#             if is_final_key and isinstance(temp_data, dict) and key in temp_data:\n",
    "#                 for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]:\n",
    "#                     if search_key in temp_data:\n",
    "#                         id_ = data\n",
    "#                         name = temp_data[search_key]\n",
    "#                         # Return the entire dictionary at this level\n",
    "#                         return {\"id\": id_, \"name\": name, \"all_keys\": temp_data}\n",
    "#             return {\"id\": data, \"name\": None, \"all_keys\": temp_data}\n",
    "\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_edge_mappings(edge_maps, provided_by):\n",
    "#     # Initialize the output dictionary\n",
    "#     relations = {}\n",
    "#     # Process each triplet\n",
    "#     for subject, predicate, obj in edge_maps:\n",
    "#         bl_pred = BMT.get_element(predicate)\n",
    "#         if bl_pred:\n",
    "#             predicate = bl_pred[\"slot_uri\"]\n",
    "#         if predicate not in relations:\n",
    "#             relations[predicate] = {\"from\": [], \"to\": [], \"provided_by\": provided_by}\n",
    "        \n",
    "#         # Add the subject to the \"from\" list if not already present\n",
    "#         if subject not in relations[predicate][\"from\"]:\n",
    "#             relations[predicate][\"from\"].append(subject)\n",
    "        \n",
    "#         # Add the object to the \"to\" list if not already present\n",
    "#         if obj not in relations[predicate][\"to\"]:\n",
    "#             relations[predicate][\"to\"].append(obj)\n",
    "\n",
    "#     # Print the resulting dictionary\n",
    "#     return relations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "********************** Current Code **********************  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmt import Toolkit\n",
    "import requests\n",
    "import pprint\n",
    "import biothings_client\n",
    "import json\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize Biolink Model Toolkit\n",
    "BMT = Toolkit() # only want to initialize once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_value(data, key_path, return_full=True):\n",
    "    \"\"\"\n",
    "    Retrieve a value from a nested dictionary using a dot-separated key path.\n",
    "    Handles lists if encountered during traversal.\n",
    "    Example: key_path = \"raresource.disease.orphanet\" will return the value of\n",
    "    data[\"raresource\"][\"disease\"][0][\"orphanet\"] if \"disease\" is a list.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The input dictionary to search.\n",
    "        key_path (str): The dot-separated key path to traverse.\n",
    "        return_full (bool): If True, return the full structure (id, name, all_keys).\n",
    "                            If False, return just the ID value.\n",
    "\n",
    "    Returns:\n",
    "        dict, list, or str: The full structure or just the ID, depending on `return_full`.\n",
    "    \"\"\"\n",
    "    keys = key_path.split(\".\")  # Split the key path into individual keys\n",
    "    temp_data = data.copy()  # For reference\n",
    "    loop_ct = 0\n",
    "\n",
    "    for i, key in enumerate(keys):\n",
    "        loop_ct += 1\n",
    "        is_final_key = (i == len(keys) - 1)\n",
    "\n",
    "        if isinstance(data, dict) and key in data:\n",
    "            temp_data = data[key]\n",
    "            if isinstance(temp_data, str):  # Found a string ID\n",
    "                id_ = temp_data\n",
    "                if not return_full:\n",
    "                    return id_  # Return just the ID if return_full is False\n",
    "                for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]:\n",
    "                    if search_key in data:\n",
    "                        name = data[search_key]\n",
    "                        break\n",
    "                    else:\n",
    "                        name = None\n",
    "                return {\"id\": id_, \"name\": name, \"all_keys\": data}\n",
    "            data = data[key]\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            if len(data) > 0:\n",
    "                if is_final_key:\n",
    "                    id_list = []\n",
    "                    for data_dict in data:\n",
    "                        if key in data_dict:\n",
    "                            id_ = data_dict[key]\n",
    "                            if not return_full:\n",
    "                                id_list.append(id_)  # Append just the ID if return_full is False\n",
    "                                continue\n",
    "                            name = None\n",
    "                            for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]:\n",
    "                                if search_key in data_dict:\n",
    "                                    name = data_dict[search_key]\n",
    "                                    break\n",
    "                            id_list.append({\"id\": id_, \"name\": name, \"all_keys\": data_dict})\n",
    "                        else:\n",
    "                            return None  # Key not found\n",
    "                    return id_list\n",
    "            else:\n",
    "                print(\"Empty list encountered.\")\n",
    "                return None\n",
    "\n",
    "        elif isinstance(data, str):\n",
    "            if is_final_key and isinstance(temp_data, dict) and key in temp_data:\n",
    "                for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]:\n",
    "                    if search_key in temp_data:\n",
    "                        id_ = data\n",
    "                        if not return_full:\n",
    "                            return id_  # Return just the ID if return_full is False\n",
    "                        name = temp_data[search_key]\n",
    "                        return {\"id\": id_, \"name\": name, \"all_keys\": temp_data}\n",
    "            return {\"id\": data, \"name\": None, \"all_keys\": temp_data}\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_biolink_data_maps(data):\n",
    "    \"\"\"\n",
    "    Create Biolink node and edge mappings from input data.\n",
    "    \"\"\"\n",
    "    node_mappings = {}\n",
    "    edge_mappings_updated = {}\n",
    "    edge_maps = []\n",
    "\n",
    "    for mkg_hit in data.get(\"hits\", {}).get(\"hits\", []):\n",
    "        hit = mkg_hit[\"_source\"]\n",
    "\n",
    "        subject = hit[\"subject\"]\n",
    "        subject_prefix = hit[\"subject_prefix\"]\n",
    "        s_uri = BMT.get_element(subject)[\"class_uri\"]\n",
    "\n",
    "        # Currently using to get subject identification path, \n",
    "        # response mapping gives object details of edge, not subject. \n",
    "        # ***** Not reliable *****\n",
    "        s_id_ref = hit[\"api\"][\"bte\"][\"query_operation\"][\"request_body\"][\"body\"].get(\"scopes\")\n",
    "        object_ = hit[\"object\"]\n",
    "        object_prefix = hit[\"object_prefix\"]\n",
    "        o_uri = BMT.get_element(object_)[\"class_uri\"]\n",
    "        # Get fields from the query operation for the object\n",
    "        o_properties = hit[\"api\"][\"bte\"][\"query_operation\"][\"params\"].get(\"fields\", \"\")\n",
    "        o_properties = [field.strip() for field in o_properties.split(\",\")]\n",
    "\n",
    "        # In the response mapping we get the object identification path,\n",
    "        # followed by additional object /edge properties.\n",
    "        o_id_ref = None\n",
    "\n",
    "\n",
    "        predicate = hit[\"predicate\"]\n",
    "        pred_element = BMT.get_element(predicate)\n",
    "        pred_uri = pred_element[\"slot_uri\"] if pred_element else None\n",
    "\n",
    "        # edge properties\n",
    "        provided_by = hit[\"api\"][\"provided_by\"]\n",
    "        agent_type = hit[\"api\"][\"bte\"][\"query_operation\"].get(\"agent_type\")\n",
    "        knowledge_level = hit[\"api\"][\"bte\"][\"query_operation\"].get(\"knowledge_level\")\n",
    "\n",
    "        # ========================\n",
    "        # EDGE MAPPING\n",
    "        # ========================\n",
    "        if pred_uri and BMT.is_translator_canonical_predicate(pred_uri):\n",
    "            if pred_uri not in edge_mappings_updated:\n",
    "                # edge_maps.append((s_uri, pred_uri, o_uri))\n",
    "                edge_rel = f\"{s_uri}-{pred_uri}-{o_uri}\"\n",
    "                edge_mappings_updated[edge_rel] = {\n",
    "                    \"subject\": s_uri,\n",
    "                    \"object\": o_uri,\n",
    "                    \"primary_knowledge_source\": provided_by,\n",
    "                    \"agent_type\": agent_type,\n",
    "                    \"knowledge_level\": knowledge_level,\n",
    "                    \"properties\": {},\n",
    "                }\n",
    "            # print(hit[\"api\"][\"bte\"][\"response_mapping\"])\n",
    "            for key, value in hit[\"api\"][\"bte\"][\"response_mapping\"].items():\n",
    "                if isinstance(value, dict):\n",
    "                    for k, v in value.items():\n",
    "                        if object_prefix in v:\n",
    "                            o_id_ref = v\n",
    "                        elif \"ref_url\" == k:\n",
    "                            edge_mappings_updated[edge_rel]['properties'][\"publications\"] = v\n",
    "                        # else:\n",
    "                            # edge_mappings_updated[pred_uri]['properties'][k] = v\n",
    "\n",
    "        # ========================\n",
    "        # NODE MAPPING: SUBJECT\n",
    "        # ========================\n",
    "        s_rel = f\"{subject_prefix}-{s_uri}\"\n",
    "        if s_rel not in node_mappings:\n",
    "            node_mappings[s_rel] = {\n",
    "                \"prefix\": subject_prefix,\n",
    "                \"identifier\": s_id_ref,\n",
    "                \"path\": s_id_ref,\n",
    "                \"properties\": {}\n",
    "            }\n",
    "\n",
    "        # ========================\n",
    "        # NODE MAPPING: OBJECT\n",
    "        # ========================\n",
    "        o_rel = f\"{object_prefix}-{o_uri}\"\n",
    "        if o_rel not in node_mappings:\n",
    "            node_mappings[o_rel] = {\n",
    "                \"prefix\": object_prefix,\n",
    "                # \"identifier\": o_id_ref,\n",
    "                # \"path\": o_id_ref,\n",
    "                \"properties\": {}\n",
    "            }\n",
    "            for key, value in hit[\"api\"][\"bte\"][\"response_mapping\"].items():\n",
    "                if isinstance(value, dict):\n",
    "                    for k, v in value.items():\n",
    "                        if object_prefix in k:\n",
    "                            node_mappings[o_rel][\"identifier\"] = v\n",
    "                        elif \"ref_url\" == k:\n",
    "                            pass\n",
    "                        else:\n",
    "                            node_mappings[o_rel][\"properties\"][k] = v\n",
    "        else:\n",
    "            for key, value in hit[\"api\"][\"bte\"][\"response_mapping\"].items():\n",
    "                if isinstance(value, dict):\n",
    "                    for k, v in value.items():\n",
    "                        if object_prefix in k:\n",
    "                            pass\n",
    "                        elif \"ref_url\" == k:\n",
    "                            pass\n",
    "                        else:\n",
    "                            node_mappings[o_rel][\"properties\"][k] = v\n",
    "            \n",
    "            # for field in o_properties:\n",
    "            #     field_key = field.split(\".\")[-1]\n",
    "            #     node_mappings[object_prefix][\"properties\"][field_key] = field \n",
    "\n",
    "\n",
    "    return node_mappings, edge_maps, edge_mappings_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_biothings_nodes(node_mappings, biothings_api_data):\n",
    "    # by data doc\n",
    "    # print(api_data['entrezgene'])\n",
    "\n",
    "    for node_uri, node_dict in node_mappings.items():\n",
    "        key_identifier = node_dict[\"identifier\"]\n",
    "        node_prefix = node_dict[\"prefix\"]\n",
    "        # Change all instance to node_uri == node_cat\n",
    "        # node_cat = node_uri #[key for key,value in node_mappings.items() if value['prefix'] == node_prefix] # why are we going through items here?\n",
    "        node_api_data = get_nested_value(biothings_api_data, key_identifier)\n",
    "        # pprint.pprint(node_api_data)\n",
    "\n",
    "        # print(f\"[INFO] Node Typ: {node_uri} | Node ID: {key_identifier} | Prefix: {node_prefix}\")\n",
    "        # print(f\"[INFO] Node category: {node_cat}\")\n",
    "        # print(f\"[INFO] type: {type(node_ids)}\")\n",
    "\n",
    "        if isinstance(node_api_data, dict):\n",
    "            unique_node_id =  f\"{node_prefix}:{node_api_data['id']}\"\n",
    "            unique_node_name = node_api_data[\"name\"] # Update logic\n",
    "\n",
    "            # print(f\"[INFO] Unique Node ID: {unique_node_id} | Unique Node Name: {unique_node_name}\")\n",
    "\n",
    "            if unique_node_id not in nodes:\n",
    "                nodes[unique_node_id] = {\n",
    "                    \"id\": unique_node_id,\n",
    "                    \"name\": unique_node_name,\n",
    "                    \"category\": [node_uri]\n",
    "                    # \"provided_by\": [node_mappings[s_uri]['provided_by']]\n",
    "                }\n",
    "\n",
    "                for prop_key, prop_value in node_dict['properties'].items():\n",
    "                    if \"cooccurrence_url\" == prop_key:\n",
    "                        continue\n",
    "                    elif \"orphanet\" == prop_key:\n",
    "                        continue\n",
    "                    if \".\" in prop_value and prop_key in node_api_data[\"all_keys\"]:\n",
    "                        nodes[unique_node_id][prop_key] = node_api_data[\"all_keys\"][prop_key]\n",
    "                    elif prop_key in  node_api_data[\"all_keys\"]:                                \n",
    "                        nodes[unique_node_id][prop_key] = node_api_data[\"all_keys\"][prop_key]\n",
    "\n",
    "        if isinstance(node_api_data, list):\n",
    "            for id_ in node_api_data:\n",
    "                unique_node_id =  f\"{node_prefix}:{id_['id']}\"\n",
    "                unique_node_name = id_[\"name\"] \n",
    "                if unique_node_id not in nodes:\n",
    "                    nodes[unique_node_id] = {\n",
    "                        \"id\": unique_node_id,\n",
    "                        \"name\": unique_node_name,\n",
    "                        \"category\": [node_uri],\n",
    "                    }\n",
    "\n",
    "                    for prop_key, prop_value in node_dict['properties'].items():\n",
    "                        if \"cooccurrence_url\" == prop_key:\n",
    "                            continue\n",
    "                        elif \"orphanet\" == prop_key:\n",
    "                            continue\n",
    "                        elif \".\" in prop_value and prop_key in id_[\"all_keys\"]:\n",
    "                            nodes[unique_node_id][prop_key] = id_[\"all_keys\"][prop_key]\n",
    "\n",
    "                        elif prop_key in  id_:                                \n",
    "                                nodes[unique_node_id][prop_key] = id_[\"all_keys\"][prop_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_biothings_edges(edge_relations, edge_mappings, node_mappings, biothings_api_data): # no edge relations\n",
    "    for p_uri, edge_map in edge_mappings.items():\n",
    "        s_uri = edge_map[\"subject\"]\n",
    "        s_node_map = node_mappings[s_uri]\n",
    "        s_api_data = get_nested_value(biothings_api_data, s_node_map[\"identifier\"])\n",
    "        if isinstance(s_api_data, dict): # should only be one subject? no list returned?\n",
    "            s_id = s_api_data[\"id\"]\n",
    "            s_id = f\"{s_node_map['prefix']}:{s_id}\"\n",
    "\n",
    "        o_uri = edge_map[\"object\"]\n",
    "        o_node_map = node_mappings[o_uri]\n",
    "        o_api_data = get_nested_value(biothings_api_data, o_node_map[\"identifier\"])\n",
    "\n",
    "        # ref_url_dict = get_nested_value(biothings_api_data, edge_map['ref_url'])\n",
    "        ref_url_path = edge_map['ref_url'].split(\".\")[-1]\n",
    "\n",
    "        if not isinstance(o_api_data, list):\n",
    "            o_api_data = [o_api_data]\n",
    "\n",
    "        for n in o_api_data:\n",
    "            if n is None:\n",
    "                # logger.info\n",
    "                # print(f\"Subject node, {s_id}, does not have an object node, {n}, api_data: {biothing_api_data}\")\n",
    "                continue\n",
    "            o_id = n[\"id\"]\n",
    "            o_id = f\"{o_node_map['prefix']}:{o_id}\"\n",
    "            rel = f\"{s_id}-{p_uri}-{o_id}\"\n",
    "            # process properties , merge key and value to edges \n",
    "            edges[rel] = {\n",
    "                \"subject\": s_id,\n",
    "                \"predicate\": p_uri,\n",
    "                \"object\": o_id,\n",
    "                \"knowledge_level\": edge_map['knowledge_level'],\n",
    "                \"agent_type\": edge_map['agent_type'],\n",
    "                \"primary_knowledge_source\": edge_map['primary_knowledge_source'],\n",
    "                # \"publications\": [n[\"all_keys\"][ref_url_path]] # assuming ref_url path alway in the object path\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_kgx_dict(nodes, edges):\n",
    "    kgx_dict = {\n",
    "        \"nodes\": list(nodes.values()),\n",
    "        \"edges\": list(edges.values())\n",
    "    }\n",
    "    return kgx_dict\n",
    "\n",
    "# def get_nodes_and_edges(node_mappings, edge_mappings,client):\n",
    "#     nodes,edges = get_biothings_api(node_mappings, client, edge_mappings)\n",
    "#     return nodes, edges\n",
    "\n",
    "# # def remove_duplicates(list_of_dicts):\n",
    "# #     Remove duplicate dictionaries from a list of dictionaries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_biothings_apis(node_mappings, edge_relations, edge_mappings, client):\n",
    "    ct=0\n",
    "    # https://biothings.ci.transltr.io/rare_source/gene/100\n",
    "    for biothings_api_data in tqdm(client.query(q=\"__all__\", fetch_all=True)):\n",
    "        extract_biothings_nodes(node_mappings, biothings_api_data)\n",
    "        extract_biothings_edges(edge_relations, edge_mappings, node_mappings, biothings_api_data) \n",
    "        ct+=1\n",
    "        # if ct >= 2:\n",
    "        #     break\n",
    "    print(f\"üìä [INFO] Extracted {ct} records from BioThings API.\")\n",
    "\n",
    "# def extract_biothings_apis(node_mappings, edge_relations, edge_mappings, client):\n",
    "#     # Define the URL\n",
    "#     url = \"https://biothings.ci.transltr.io/rare_source/gene/100\"\n",
    "#     print(f\"[INFO] Extracting from URL: {url}\")\n",
    "#     # Make the GET request\n",
    "#     responseX = requests.get(url)\n",
    "#     # Check if the request was successful\n",
    "#     if responseX.status_code == 200:\n",
    "#         # Parse the JSON response\n",
    "#         biothings_api_data = responseX.json()\n",
    "#         extract_biothings_nodes(node_mappings, biothings_api_data)\n",
    "#         extract_biothings_edges(edge_relations, edge_mappings, node_mappings, biothings_api_data)\n",
    "\n",
    "    # return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kgx_pipeline(data, client, debug=False):\n",
    "    print(\"\\nüöÄ [INFO] Starting KGx conversion pipeline...\")\n",
    "    # === Global Initialization ===\n",
    "    global nodes, edges\n",
    "    nodes = {}\n",
    "    edges = {}\n",
    "\n",
    "    # === Step 1: Create Biolink mappings from SmartAPI metadata ===\n",
    "    print(\"üõ†Ô∏è [INFO] Creating Biolink mappings...\")\n",
    "    node_mappings, edge_relations, edge_mappings = make_biolink_data_maps(data)\n",
    "\n",
    "    # === Step 1.1: Add hardcoded property mappings for Disease and Gene ===\n",
    "    disease_dict = {\n",
    "        \"omim\": \"raresource.disease.omim\",\n",
    "        \"gard\": \"raresource.disease.gard\",\n",
    "        \"umls\": \"raresource.disease.umls\",\n",
    "        \"mesh\": \"raresource.disease.mesh\",\n",
    "        \"name\": \"raresource.disease.name\",\n",
    "        \"icd10cm\": \"raresource.disease.icd10cm\"\n",
    "    }\n",
    "\n",
    "    gene_dict = {\n",
    "        \"hgnc\": \"hgnc\",\n",
    "        \"ensemblgene\": \"ensemblgene\",\n",
    "        \"symbol\": \"symbol\",\n",
    "        \"description\": \"description\"\n",
    "    }\n",
    "\n",
    "    for s_uri, mapping in node_mappings.items():\n",
    "        props = mapping.get(\"properties\", {})\n",
    "        if \"Disease\" in s_uri:\n",
    "            for key, val in disease_dict.items():\n",
    "                props.setdefault(key, val)\n",
    "\n",
    "        if \"Gene\" in s_uri:\n",
    "            for key, val in gene_dict.items():\n",
    "                props.setdefault(key, val)\n",
    "\n",
    "        # Remove overly generic 'disease' field\n",
    "        props.pop(\"disease\", None)\n",
    "        mapping[\"properties\"] = props\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n[DEBUG] Node Mappings:\")\n",
    "        pprint.pprint(node_mappings, indent=4)\n",
    "\n",
    "        print(\"\\n[DEBUG] Edge Mappings:\")\n",
    "        pprint.pprint(edge_mappings, indent=4)\n",
    "    # # === Step 2: Extract nodes and edges using BioThings API ===\n",
    "    # print(\"\\nüîÑ [INFO] Extracting nodes and edges from BioThings API...\")\n",
    "    # extract_biothings_apis(node_mappings, edge_relations, edge_mappings, client)\n",
    "\n",
    "    # # if debug:\n",
    "    # print(f\"üìä [INFO] Extracted {len(nodes)} nodes and {len(edges)} edges\")\n",
    "\n",
    "    # # === Step 3: Format the graph as KGX-compatible dictionary ===\n",
    "    # print(\"üì¶ [INFO] Formatting graph as KGX-compatible dictionary...\")\n",
    "    # kgx_dict = format_kgx_dict(nodes, edges)\n",
    "\n",
    "    # print(\"‚úÖ [INFO] Formatted dictionary\")\n",
    "    # return kgx_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_kgx_to_json(kgx_data, output_file):\n",
    "    # Write the dictionary to a JSON file\n",
    "    with open(output_file, \"w\") as json_file:\n",
    "        json.dump(kgx_data, json_file, indent=4)  # Use indent for pretty formatting\n",
    "    print(f\"\\nüìù [INFO] KGX data written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_kgx_to_jsonl(kgx_data, nodes_jsonl_file, edges_jsonl_file):\n",
    "    # Write nodes to JSONL\n",
    "    with open(nodes_jsonl_file, \"w\") as nodes_file:\n",
    "        for node in kgx_data[\"nodes\"]:\n",
    "            json_str = json.dumps(node)\n",
    "            nodes_file.write(json_str + \"\\n\")\n",
    "            # json_str = json.dumps(node, separators=(', ', ': '))\n",
    "            # json_str = json_str.replace('{', '{ ', 1)  # add space after first '{'\n",
    "            # nodes_file.write(json_str + \"\\n\")\n",
    "\n",
    "    # Write edges to JSONL\n",
    "    with open(edges_jsonl_file, \"w\") as edges_file:\n",
    "        for edge in kgx_data[\"edges\"]:\n",
    "            json_str = json.dumps(edge)\n",
    "            edges_file.write(json_str + \"\\n\")\n",
    "            # json_str = json.dumps(edge, separators=(', ', ': '))\n",
    "            # json_str = json_str.replace('{', '{ ', 1)  # add space after first '{'\n",
    "            # edges_file.write(json_str + \"\\n\")\n",
    "\n",
    "    print(f\"üìù [INFO] KGx nodes written to {nodes_jsonl_file}\")\n",
    "    print(f\"üìù [INFO] KGx edges written to {edges_jsonl_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying SmartAPI: https://smart-api.info/api/metakg/?q=api.smartapi.id:b772ebfbfa536bba37764d7fddb11d6f&bte=1&meta=1&consolidated=0&size=100\n",
      "\n",
      "üöÄ [INFO] Starting KGx conversion pipeline...\n",
      "üõ†Ô∏è [INFO] Creating Biolink mappings...\n",
      "\n",
      "[DEBUG] Node Mappings:\n",
      "{   'NCBIGene-biolink:Gene': {   'identifier': 'entrezgene',\n",
      "                                 'path': 'entrezgene',\n",
      "                                 'prefix': 'NCBIGene',\n",
      "                                 'properties': {   'description': 'description',\n",
      "                                                   'ensemblgene': 'ensemblgene',\n",
      "                                                   'hgnc': 'hgnc',\n",
      "                                                   'output_name': 'symbol',\n",
      "                                                   'symbol': 'symbol'}},\n",
      "    'UMLS-biolink:Disease': {   'identifier': 'raresource.disease.umls',\n",
      "                                'prefix': 'UMLS',\n",
      "                                'properties': {   'gard': 'raresource.disease.gard',\n",
      "                                                  'icd10cm': 'raresource.disease.icd10cm',\n",
      "                                                  'mesh': 'raresource.disease.mesh',\n",
      "                                                  'name': 'raresource.disease.name',\n",
      "                                                  'omim': 'raresource.disease.omim',\n",
      "                                                  'umls': 'raresource.disease.umls'}},\n",
      "    'orphanet-biolink:Disease': {   'identifier': 'raresource.disease.orphanet',\n",
      "                                    'prefix': 'orphanet',\n",
      "                                    'properties': {   'gard': 'raresource.disease.gard',\n",
      "                                                      'icd10cm': 'raresource.disease.icd10cm',\n",
      "                                                      'mesh': 'raresource.disease.mesh',\n",
      "                                                      'name': 'raresource.disease.name',\n",
      "                                                      'omim': 'raresource.disease.omim',\n",
      "                                                      'umls': 'raresource.disease.umls'}}}\n",
      "\n",
      "[DEBUG] Edge Mappings:\n",
      "{   'biolink:Gene-biolink:gene_associated_with_condition-biolink:Disease': {   'agent_type': 'manual_agent',\n",
      "                                                                               'knowledge_level': 'knowledge_assertion',\n",
      "                                                                               'object': 'biolink:Disease',\n",
      "                                                                               'primary_knowledge_source': 'infores:rare-source',\n",
      "                                                                               'properties': {   'publications': 'raresource.disease.cooccurrence_url'},\n",
      "                                                                               'subject': 'biolink:Gene'}}\n"
     ]
    }
   ],
   "source": [
    "api_name = \"rare_source\"\n",
    "api_id = \"b772ebfbfa536bba37764d7fddb11d6f\"\n",
    "client = biothings_client.get_client(url=f\"https://biothings.ci.transltr.io/{api_name}\")\n",
    "\n",
    "# Construct the SmartAPI query URL\n",
    "smartapi_url = f\"https://smart-api.info/api/metakg/?q=api.smartapi.id:{api_id}&bte=1&meta=1&consolidated=0&size=100\"\n",
    "print(f\"Querying SmartAPI: {smartapi_url}\")\n",
    "\n",
    "# Send the request and retrieve data\n",
    "response = requests.get(smartapi_url)\n",
    "data = response.json()\n",
    "kgx_dict = run_kgx_pipeline(data, client, debug=True)\n",
    "# if kgx_dict:\n",
    "#     print(f\"üü¢ KGX pipeline executed successfully.\")\n",
    "# else:\n",
    "#     print(f\"üî¥ KGX pipeline execution failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù [INFO] KGX data written to raresource_kgx_1-doc.json\n"
     ]
    }
   ],
   "source": [
    "write_kgx_to_json(kgx_dict, \"raresource_kgx_1-doc.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù [INFO] KGx nodes written to raresource_nodes_1-doc_.jsonl\n",
      "üìù [INFO] KGx edges written to raresource_edges_1-doc_.jsonl\n"
     ]
    }
   ],
   "source": [
    "nodes_jsonl_file = \"raresource_nodes_1-doc_.jsonl\"\n",
    "edges_jsonl_file = \"raresource_edges_1-doc_.jsonl\"\n",
    "\n",
    "write_kgx_to_jsonl(kgx_dict, nodes_jsonl_file, edges_jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KGX][jsonl_source.py][               parse] WARNING: Parse function cannot resolve the KGX file type in name raresource_nodes_full.jsonl. Skipped...\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# def kgx_validate():\n",
    "!kgx validate -i jsonl \"raresource_nodes_full.jsonl\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
