{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ---\n",
    "\n",
    "\n",
    "### **KGX Format Overview**\n",
    "\n",
    "KGX (Knowledge Graph Exchange) is a Python library and set of utilities for exchanging knowledge graphs (KGs) that conform to the Biolink Model. It provides tools for converting, validating, and exchanging knowledge graphs in various formats, including JSON, TSV, RDF, and Neo4j.\n",
    "\n",
    "#### **Core Features**\n",
    "- **Property Graph Representation**: Internally represented as a `networkx.MultiDiGraph`.\n",
    "- **Biolink Model Compliance**: Ensures nodes and edges conform to the Biolink Model, including valid categories, predicates, and properties.\n",
    "- **Supported Formats**:\n",
    "  - RDF (read/write) and SPARQL endpoints (read).\n",
    "  - Neo4j endpoints (read) or dumps (write).\n",
    "  - CSV/TSV and JSON.\n",
    "  - Reasoner Standard API format.\n",
    "  - OBOGraph JSON format.\n",
    "\n",
    "\n",
    "### **KGX Format Details**\n",
    "\n",
    "#### **Node Record**\n",
    "Each node in a KGX graph is represented as a **Node Record** with the following elements:\n",
    "\n",
    "- **Required Elements**:\n",
    "  - `id`: A CURIE uniquely identifying the node.\n",
    "  - `category`: A list of Biolink Model categories describing the node.\n",
    "\n",
    "- **Optional Elements**:\n",
    "  - **Biolink Model Properties**: e.g., `name`, `description`, `xref`, `provided_by`.\n",
    "  - **Non-Biolink Properties**: Custom properties not defined in the Biolink Model.\n",
    "\n",
    "#### **Edge Record**\n",
    "Each edge in a KGX graph is represented as an **Edge Record** with the following elements:\n",
    "\n",
    "- **Required Elements**:\n",
    "  - `subject`: The source node's `id`.\n",
    "  - `predicate`: The relationship type (from the Biolink `related_to` hierarchy).\n",
    "  - `object`: The target node's `id`.\n",
    "\n",
    "- **Optional Elements**:\n",
    "  - **Biolink Model Properties**: e.g., `category`, `publications`.\n",
    "  - **Edge Provenance**: e.g., `primary_knowledge_source`, `supporting_data_source`.\n",
    "\n",
    "\n",
    "### **KGX Format Examples**\n",
    "\n",
    "#### **KGX JSON Format**\n",
    "The JSON format represents the graph as a dictionary with `nodes` and `edges` arrays.\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **KGX TSV Format**\n",
    "The TSV format separates nodes and edges into two files: `nodes.tsv` and `edges.tsv`.\n",
    "\n",
    "**nodes.tsv**:\n",
    "| id            | category                                                                 | name                                  | provided_by               |\n",
    "|---------------|--------------------------------------------------------------------------|---------------------------------------|---------------------------|\n",
    "| HGNC:11603    | biolink:NamedThing\\|biolink:BiologicalEntity\\|biolink:Gene               | TBX4                                  | MonarchArchive:gwascatalog |\n",
    "| MONDO:0005002 | biolink:NamedThing\\|biolink:BiologicalEntity\\|biolink:DiseaseOrPhenotypicFeature\\|biolink:Disease | chronic obstructive pulmonary disease | MonarchArchive:gwascatalog |\n",
    "\n",
    "**edges.tsv**:\n",
    "| id                                    | subject     | predicate                  | object         | relation   | primary_knowledge_source | category                        | publications               |\n",
    "|---------------------------------------|-------------|----------------------------|----------------|------------|---------------------------|---------------------------------|---------------------------|\n",
    "| urn:uuid:5b06e86f-d768-4cd9-ac27-abe31e95ab1e | HGNC:11603  | biolink:contributes_to    | MONDO:0005002  | RO:0003304 | MonarchArchive:gwascatalog | biolink:GeneToDiseaseAssociation | PMID:26634245\\|PMID:26634244 |\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "- **Validation**: KGX ensures that nodes and edges conform to the Biolink Model.\n",
    "- **Flexibility**: Supports both Biolink and non-Biolink properties.\n",
    "- **Interoperability**: Facilitates exchange between different graph systems and formats.\n",
    "\n",
    "Documntation: [KGX documentation](https://github.com/biolink/kgx).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************** Draft Code ********************** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# # Get the ID prefix priority list for biolink:Disease\n",
    "# element = BMT.get_element_by_mapping(\"orphanet:39041\")\n",
    "# print(element)\n",
    "# # preferred_prefixes = element\n",
    "# # print(preferred_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NCBIGene:100'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'disease_prefix': get_preferred_prefix('orphanet:39041')  # → 'MONDO'\n",
    "get_preferred_id('NCBIGene:100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BMT.get_element_by_mapping(\"orphanet:277\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BMT.is_translator_canonical_predicate(\"biolink:gene_associated_with_condition\")\n",
    "# BMT.is_symmetric(\"biolink:gene_associated_with_condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_norm = f\"https://nodenorm.ci.transltr.io/1.5/get_normalized_nodes?curie={CURIE}&conflate=false&drug_chemical_conflate=false&description=false&individual_types=false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_preferred_id(curie):\n",
    "#     url = f\"https://nodenorm.ci.transltr.io/1.5/get_normalized_nodes?curie={curie}&conflate=false&drug_chemical_conflate=false&description=false&individual_types=false\"\n",
    "\n",
    "#     response = requests.get(url)\n",
    "#     if response.ok:\n",
    "#         data = response.json()\n",
    "#         norm = data.get(curie)\n",
    "#         if norm and 'id' in norm:\n",
    "#             identifier = norm['id']['identifier']\n",
    "#             # return identifier.split(\":\")[0]  # e.g., MONDO\n",
    "#             return identifier\n",
    "#     return curie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************** Original Code ********************** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_biothings_api(node_mappings, edge_mappings, bt_data): # abstract out for one record\n",
    "#     # Iterate through BioThings API data    \n",
    "#     # Extract node data based on Biolink mappings\n",
    "#     # print('[INFO] BT data:', bt_data)\n",
    "\n",
    "#     for pred_uri, value in edge_mappings.items():\n",
    "#         # print(f\"[INFO] Predicate URI: {pred_uri} | Value: {value}\")\n",
    "#         # print(value.keys())\n",
    "#         s_uri = value[\"subject\"]\n",
    "#         o_uri = value[\"object\"]\n",
    "#         # print(f\"[INFO] Subject URI: {s_uri} | Object URI: {o_uri}\")\n",
    "#         s_data = node_mappings[s_uri]\n",
    "#         o_data = node_mappings[o_uri]\n",
    "#         # print(f\"[INFO] Subject data: {s_data} | Object data: {o_data}\")\n",
    "#         s_identifier_key = s_data['identifier']\n",
    "#         o_identifier_key = o_data['identifier']\n",
    "#         s_prefix = s_data['prefix']\n",
    "#         o_prefix = o_data['prefix']\n",
    "#         s_category = [key for key,value in node_mappings.items() if value['prefix'] == s_prefix]\n",
    "#         o_category = [key for key,value in node_mappings.items() if value['prefix'] == o_prefix]\n",
    "#         # s_prefix = s_data['prefix']\n",
    "#         # s_category\n",
    "\n",
    "#         # try:\n",
    "#         s_identifiers = get_nested_value(bt_data,s_identifier_key)\n",
    "#         o_identifiers = get_nested_value(bt_data,o_identifier_key)\n",
    "#         if o_identifiers is None or s_identifiers is None:\n",
    "#             # print(f\"[INFO] Found subject identifiers: {s_identifiers} key: {s_identifier_key} \\n\")\n",
    "#             # print(f\"[INFO] Found object identifiers:{o_identifiers} key: {o_identifier_key}\")\n",
    "#             continue\n",
    "#         # print(f\"[INFO] Found subject identifiers: {s_identifiers} key: {s_identifier_key} \\n\")\n",
    "#         # ******************************************\n",
    "#         # Create Nodes\n",
    "#         for s_ in s_identifiers:\n",
    "#             s_node_id =  f\"{s_prefix}:{s_[0]}\"\n",
    "#             s_node_name = s_[1] \n",
    "#             # s_node_norm_id = get_preferred_id(s_node_id)  # Use '=' for assignment\n",
    "#             # print(f\"[INFO] {s_node_id} | {s_node_name}\")\n",
    "#             if s_node_id not in nodes:\n",
    "#                 nodes[s_node_id] = {\n",
    "#                     \"id\": s_node_id,\n",
    "#                     \"name\": s_node_name,\n",
    "#                     \"category\": s_category\n",
    "#                     # \"provided_by\": [node_mappings[s_uri]['provided_by']]\n",
    "#                 }\n",
    "#                 for prop_key, prop_value in node_mappings[s_uri]['properties'].items():\n",
    "#                     # print(prop_key)\n",
    "#                     if \".\" in prop_value:\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         if prop_key in prop_value:\n",
    "#                             v_ = bt_data[prop_key]\n",
    "#                             nodes[s_node_id][prop_key] = v_\n",
    "                        \n",
    "#                 # pprint.pprint(nodes[s_node_id])\n",
    "#             for o_ in o_identifiers:\n",
    "#                 o_node_id =  f\"{o_prefix}:{o_[0]}\"\n",
    "#                 o_node_name = o_[1]\n",
    "#                 o_node_norm_id = get_preferred_id(o_node_id)\n",
    "#                 # print(f\"[INFO] {o_node_id} | {o_node_name}\")\n",
    "#                 if o_node_id not in nodes:\n",
    "#                     nodes[o_node_id] = {\n",
    "#                         \"id\": o_node_id,\n",
    "#                         \"name\": o_node_name,\n",
    "#                         \"category\": o_category\n",
    "#                         # \"provided_by\": [node_mappings[o_uri]['provided_by']]\n",
    "#                     }\n",
    "#                     for prop_key, prop_value in node_mappings[o_uri]['properties'].items():\n",
    "#                         if \".\" in prop_value:                            \n",
    "#                             nested_ids = get_nested_value(bt_data, prop_value)\n",
    "#                             if nested_ids is not None:\n",
    "#                                 for nest_id in nested_ids:\n",
    "#                                     nodes[o_node_id][prop_key.split(\".\")[-1]] = nest_id[0]\n",
    "#                         else:\n",
    "#                             if prop_key in bt_data:\n",
    "#                                 v_ = bt_data[prop_key]\n",
    "#                                 nodes[o_node_id][prop_key] = v_\n",
    "#                 # pprint.pprint(nodes[o_node_id])\n",
    "#                 # ******************************************\n",
    "#                 # Create Edges\n",
    "#                 is_canonical = BMT.is_translator_canonical_predicate(pred_uri)\n",
    "#                 is_symmetric = BMT.is_symmetric(pred_uri)\n",
    "\n",
    "#                 if is_canonical:\n",
    "#                     print(f\"[INFO] Predicate is canonical: {pred_uri} | {is_canonical}\")\n",
    "#                     # if is_symmetric:\n",
    "#                     #     print(f\"[INFO] {pred_uri} is also symmetric (this is unusual for canonical predicates).\")\n",
    "#                     # else:\n",
    "#                     #     print(f\"[INFO] {pred_uri} is NOT symmetric (expected for canonical predicates).\")\n",
    "#                     rel = f\"{s_node_id}-{pred_uri}-{o_node_id}\"\n",
    "#                     if rel not in edges:\n",
    "#                         ref_url = get_nested_value(bt_data, edge_mappings[pred_uri]['properties']['ref_url'])\n",
    "#                         print(ref_url)\n",
    "#                         edges[rel] = {\n",
    "#                             \"subject\": s_node_id,\n",
    "#                             \"predicate\": pred_uri,\n",
    "#                             \"object\": o_node_id,\n",
    "#                             \"knowledge_level\": edge_mappings[pred_uri]['knowledge_level'],\n",
    "#                             \"agent_type\": edge_mappings[pred_uri]['agent_type'],\n",
    "#                             \"primary_knowledge_source\": edge_mappings[pred_uri]['primary_knowledge_source'],\n",
    "#                             \"ref_url\":[ y_[0][0] for y_ in ref_url],\n",
    "                            \n",
    "#                         }\n",
    "\n",
    "#         except Exception as error:\n",
    "#             # print(f\"\\n[INFO] ERROR: {error}\\n\")\n",
    "#             pass\n",
    "\n",
    "#     return nodes,edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_nested_value(data, key_path):\n",
    "#     \"\"\"\n",
    "#     # Biothings Util function? \n",
    "#     Retrieve a value from a nested dictionary using a dot-separated key path.\n",
    "#     Handles lists if encountered during traversal.\n",
    "#     Example: key_path = \"raresource.disease.orphanet\" will return the value of\n",
    "#     data[\"raresource\"][\"disease\"][0][\"orphanet\"] if \"disease\" is a list.\n",
    "#     \"\"\"\n",
    "\n",
    "#     keys = key_path.split(\".\")  # Split the key path into individual keys\n",
    "#     temp_data=data.copy() # for reference\n",
    "#     loop_ct=0\n",
    "\n",
    "#     # print('here')\n",
    "#     for i, key in enumerate(keys):\n",
    "#         # print(key)\n",
    "#         # print(\"in loop...\")\n",
    "#         loop_ct+=1\n",
    "#         is_final_key = (i == len(keys) - 1)\n",
    "#         # data=data[key]\n",
    "#         # print(key, type(data), loop_ct)\n",
    "#         # print(f\"Starting data: {type(data)} {type(temp_data)} {key}\" )\n",
    "#         # *********************************************************************************************************\n",
    "#         if isinstance(data, dict) and key in data:\n",
    "#             # print(f\"[INFO] Dictionary loop on key: {key}\")\n",
    "#             if key in data:\n",
    "#                 temp_data = data[key]\n",
    "#                 if isinstance(temp_data, str): # found a string ID\n",
    "#                     id_ = temp_data\n",
    "#                     # print(f\"[INFO] Inside string ID instance: {key}, {id_}\")\n",
    "#                     # print(data.keys())\n",
    "#                     for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]: # **MAKE REGEX** (drug_name, etc...)\n",
    "#                         if search_key in data:\n",
    "#                             name = data[search_key]\n",
    "#                             break\n",
    "#                         else:\n",
    "#                             name = None\n",
    "#                     return [(id_, name)]\n",
    "#                 data = data[key]\n",
    "#             else:\n",
    "#                 # print(f\"Key {key} not found in dictionary.\")\n",
    "#                 return None\n",
    "#             # print(f\"Ending data: {type(data)} {type(temp_data)} {key}\\n\" )\n",
    "#         # *********************************************\n",
    "#         elif isinstance(data, list):\n",
    "#             # print(f\"[INFO] List loop on key: {key}\")\n",
    "#             # If the current data is a list, assume we want the first element\n",
    "#             if len(data) > 0:\n",
    "#                 # print(data)\n",
    "#                 if is_final_key:\n",
    "#                     # print(\"[INFO] is final key\", key)\n",
    "#                     id_list = []\n",
    "#                     for data_dict in data:\n",
    "#                         if key in data_dict:\n",
    "#                             # print(\"[INFO] found key \", key)\n",
    "#                             id_ = data_dict[key]\n",
    "#                             # print(\"\\n\", id_, key)\n",
    "#                             # pprint.pprint(data_dict)\n",
    "#                             name = None\n",
    "#                             for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\",\"drug_name\"]: # **MAKE REGEX** (drug_name, etc...)\n",
    "#                                 if search_key in data_dict:\n",
    "#                                     name = data_dict[search_key]\n",
    "#                                     break\n",
    "#                             id_list.append((id_, name))\n",
    "#                         else:\n",
    "#                             return None # key not found -- this does happen , i.e orphanet in raresource\n",
    "#                     # print(f\"Returning from list: {id_list}\")\n",
    "#                     return id_list\n",
    "#                 # temp_data = temp_data[key]\n",
    "#                 # data = data[key]\n",
    "#             else:\n",
    "#                 print(\"Empty list encountered.\")\n",
    "#                 return None\n",
    "#         # *********************************************\n",
    "#         elif isinstance(data, str):\n",
    "#             print(f\"[INFO] String loop on key: {key}\")\n",
    "\n",
    "#             # If this is the final key, check for specific keys in the list element\n",
    "#             if is_final_key and isinstance(temp_data, dict) and key in temp_data:\n",
    "#                 for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]: # **MAKE REGEX** (drug_name, etc...)\n",
    "#                     if search_key in temp_data:\n",
    "#                         id_ = data\n",
    "#                         name = temp_data[search_key]\n",
    "#                         # print(f\"Returning from list: {id_} | {name}\")\n",
    "#                         return [(id_, name)]\n",
    "#             return(data, None)\n",
    "#         # *********************************************\n",
    "#         else:\n",
    "#             ...\n",
    "#         # *********************************************************************************************************\n",
    "        \n",
    "\n",
    "#     return None\n",
    "\n",
    "def get_nested_value(data, key_path):\n",
    "    \"\"\"\n",
    "    Retrieve a value from a nested dictionary using a dot-separated key path.\n",
    "    Handles lists if encountered during traversal.\n",
    "    Example: key_path = \"raresource.disease.orphanet\" will return the value of\n",
    "    data[\"raresource\"][\"disease\"][0][\"orphanet\"] if \"disease\" is a list.\n",
    "    \"\"\"\n",
    "\n",
    "    keys = key_path.split(\".\")  # Split the key path into individual keys\n",
    "    temp_data = data.copy()  # For reference\n",
    "    loop_ct = 0\n",
    "\n",
    "    for i, key in enumerate(keys):\n",
    "        loop_ct += 1\n",
    "        is_final_key = (i == len(keys) - 1)\n",
    "\n",
    "        if isinstance(data, dict) and key in data:\n",
    "            temp_data = data[key]\n",
    "            if isinstance(temp_data, str):  # Found a string ID\n",
    "                id_ = temp_data\n",
    "                for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]:\n",
    "                    if search_key in data:\n",
    "                        name = data[search_key]\n",
    "                        break\n",
    "                    else:\n",
    "                        name = None\n",
    "                # Return the entire dictionary at this level\n",
    "                return {\"id\": id_, \"name\": name, \"all_keys\": data}\n",
    "            data = data[key]\n",
    "\n",
    "        elif isinstance(data, list):\n",
    "            if len(data) > 0:\n",
    "                if is_final_key:\n",
    "                    id_list = []\n",
    "                    for data_dict in data:\n",
    "                        if key in data_dict:\n",
    "                            id_ = data_dict[key]\n",
    "                            name = None\n",
    "                            for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]:\n",
    "                                if search_key in data_dict:\n",
    "                                    name = data_dict[search_key]\n",
    "                                    break\n",
    "                            # Return the entire dictionary at this level\n",
    "                            id_list.append({\"id\": id_, \"name\": name, \"all_keys\": data_dict})\n",
    "                        else:\n",
    "                            return None  # Key not found\n",
    "                    return id_list\n",
    "            else:\n",
    "                print(\"Empty list encountered.\")\n",
    "                return None\n",
    "\n",
    "        elif isinstance(data, str):\n",
    "            if is_final_key and isinstance(temp_data, dict) and key in temp_data:\n",
    "                for search_key in [\"SYMBOL\", \"symbol\", \"NAME\", \"name\", \"drug_name\"]:\n",
    "                    if search_key in temp_data:\n",
    "                        id_ = data\n",
    "                        name = temp_data[search_key]\n",
    "                        # Return the entire dictionary at this level\n",
    "                        return {\"id\": id_, \"name\": name, \"all_keys\": temp_data}\n",
    "            return {\"id\": data, \"name\": None, \"all_keys\": temp_data}\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_edge_mappings(edge_maps, provided_by):\n",
    "#     # Initialize the output dictionary\n",
    "#     relations = {}\n",
    "#     # Process each triplet\n",
    "#     for subject, predicate, obj in edge_maps:\n",
    "#         bl_pred = BMT.get_element(predicate)\n",
    "#         if bl_pred:\n",
    "#             predicate = bl_pred[\"slot_uri\"]\n",
    "#         if predicate not in relations:\n",
    "#             relations[predicate] = {\"from\": [], \"to\": [], \"provided_by\": provided_by}\n",
    "        \n",
    "#         # Add the subject to the \"from\" list if not already present\n",
    "#         if subject not in relations[predicate][\"from\"]:\n",
    "#             relations[predicate][\"from\"].append(subject)\n",
    "        \n",
    "#         # Add the object to the \"to\" list if not already present\n",
    "#         if obj not in relations[predicate][\"to\"]:\n",
    "#             relations[predicate][\"to\"].append(obj)\n",
    "\n",
    "#     # Print the resulting dictionary\n",
    "#     return relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_biolink_data_maps(data):\n",
    "#     \"\"\"\n",
    "#     Create Biolink node and edge mappings from input data.\n",
    "#     \"\"\"\n",
    "#     node_mappings = {}\n",
    "#     edge_mappings_updated = {}\n",
    "#     edge_maps = []\n",
    "\n",
    "#     for mkg_hit in data.get(\"hits\", {}).get(\"hits\", []):\n",
    "#         hit = mkg_hit[\"_source\"]\n",
    "\n",
    "#         subject = hit[\"subject\"]\n",
    "#         subject_prefix = hit[\"subject_prefix\"]\n",
    "#         s_uri = BMT.get_element(subject)[\"class_uri\"]\n",
    "\n",
    "#         # Currently using to get subject identification path, \n",
    "#         # response mapping gives object details of edge, not subject. \n",
    "#         # ***** Not reliable *****\n",
    "#         s_id_ref = hit[\"api\"][\"bte\"][\"query_operation\"][\"request_body\"][\"body\"].get(\"scopes\")\n",
    "\n",
    "#         object_ = hit[\"object\"]\n",
    "#         object_prefix = hit[\"object_prefix\"]\n",
    "#         o_uri = BMT.get_element(object_)[\"class_uri\"]\n",
    "#         # Get fields from the query operation for the object\n",
    "#         o_properties = hit[\"api\"][\"bte\"][\"query_operation\"][\"params\"].get(\"fields\", \"\")\n",
    "#         o_properties = [field.strip() for field in o_properties.split(\",\")]\n",
    "\n",
    "#         # In the response mapping we get the object identification path,\n",
    "#         # followed by additional object /edge properties.\n",
    "#         # o_id_ref = None\n",
    "\n",
    "#         predicate = hit[\"predicate\"]\n",
    "#         pred_element = BMT.get_element(predicate)\n",
    "#         pred_uri = pred_element[\"slot_uri\"] if pred_element else None\n",
    "\n",
    "#         # edge properties\n",
    "#         provided_by = hit[\"api\"][\"provided_by\"]\n",
    "#         agent_type = hit[\"api\"][\"bte\"][\"query_operation\"].get(\"agent_type\")\n",
    "#         knowledge_level = hit[\"api\"][\"bte\"][\"query_operation\"].get(\"knowledge_level\")\n",
    "\n",
    "#         # ========================\n",
    "#         # EDGE MAPPING\n",
    "#         # ========================\n",
    "#         if pred_uri and BMT.is_translator_canonical_predicate(pred_uri):\n",
    "#             if pred_uri not in edge_mappings_updated:\n",
    "#                 # edge_maps.append((s_uri, pred_uri, o_uri))\n",
    "#                 edge_rel = f\"{s_uri}-{pred_uri}-{o_uri}\"\n",
    "#                 edge_mappings_updated[edge_rel] = {\n",
    "#                     \"subject\": s_uri,\n",
    "#                     \"object\": o_uri,\n",
    "#                     \"primary_knowledge_source\": provided_by,\n",
    "#                     \"agent_type\": agent_type,\n",
    "#                     \"knowledge_level\": knowledge_level,\n",
    "#                     \"properties\": {},\n",
    "#                 }\n",
    "#             # print(hit[\"api\"][\"bte\"][\"response_mapping\"])\n",
    "#             for key, value in hit[\"api\"][\"bte\"][\"response_mapping\"].items():\n",
    "#                 if isinstance(value, dict):\n",
    "#                     for k, v in value.items():\n",
    "#                         if object_prefix in v:\n",
    "#                             o_id_ref = v\n",
    "#                         elif \"ref_url\" == k:\n",
    "#                             edge_mappings_updated[edge_rel]['properties'][\"publications\"] = v\n",
    "#                         # else:\n",
    "#                         #     edge_mappings_updated[pred_uri]['properties'][k] = v\n",
    "\n",
    "#         # ========================\n",
    "#         # NODE MAPPING: SUBJECT\n",
    "#         # ========================\n",
    "#         s_rel = f\"{subject_prefix}-{s_uri}\"\n",
    "#         if s_rel not in node_mappings:\n",
    "#             node_mappings[s_rel] = {\n",
    "#                 \"prefix\": subject_prefix,\n",
    "#                 \"identifier\": s_id_ref,\n",
    "#                 \"path\": s_id_ref,\n",
    "#                 \"properties\": {}\n",
    "#             }\n",
    "\n",
    "#         # ========================\n",
    "#         # NODE MAPPING: OBJECT\n",
    "#         # ========================\n",
    "#         o_rel = f\"{object_prefix}-{o_uri}\"\n",
    "#         if o_rel not in node_mappings:\n",
    "#             node_mappings[o_rel] = {\n",
    "#                 \"prefix\": object_prefix,\n",
    "#                 # \"identifier\": o_id_ref,\n",
    "#                 # \"path\": o_id_ref,\n",
    "#                 \"properties\": {}\n",
    "#             }\n",
    "#             for key, value in hit[\"api\"][\"bte\"][\"response_mapping\"].items():\n",
    "#                 if isinstance(value, dict):\n",
    "#                     for k, v in value.items():\n",
    "#                         if object_prefix in k:\n",
    "#                             node_mappings[o_rel][\"identifier\"] = v\n",
    "#                         elif \"ref_url\" == k:\n",
    "#                             pass\n",
    "#                         else:\n",
    "#                             node_mappings[o_rel][\"properties\"][k] = v\n",
    "#         else:\n",
    "#             for key, value in hit[\"api\"][\"bte\"][\"response_mapping\"].items():\n",
    "#                 if isinstance(value, dict):\n",
    "#                     for k, v in value.items():\n",
    "#                         if object_prefix in k:\n",
    "#                             pass\n",
    "#                         elif \"ref_url\" == k:\n",
    "#                             pass\n",
    "#                         else:\n",
    "#                             node_mappings[o_rel][\"properties\"][k] = v\n",
    "            \n",
    "#             # for field in o_properties:\n",
    "#             #     field_key = field.split(\".\")[-1]\n",
    "#             #     node_mappings[object_prefix][\"properties\"][field_key] = field \n",
    "\n",
    "\n",
    "#     return node_mappings, edge_mappings_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_nested_value(data, key_path, return_full=True):\n",
    "#     \"\"\"\n",
    "#     Retrieve a value from a nested dictionary using a dot-separated key path.\n",
    "#     Handles lists if encountered during traversal.\n",
    "#     Example: key_path = \"raresource.disease.orphanet\" will return the value of\n",
    "#     data[\"raresource\"][\"disease\"][0][\"orphanet\"] if \"disease\" is a list.\n",
    "\n",
    "#     Args:\n",
    "#         data (dict): The input dictionary to search.\n",
    "#         key_path (str): The dot-separated key path to traverse.\n",
    "#         return_full (bool): If True, return the full structure (id, name, all_keys).\n",
    "#                             If False, return just the ID value.\n",
    "\n",
    "#     Returns:\n",
    "#         dict, list, or str: The full structure or just the ID, depending on `return_full`.\n",
    "#     \"\"\"\n",
    "#     keys = key_path.split(\".\")  # Split the key path into individual keys\n",
    "#     temp_data = data.copy()  # For reference\n",
    "#     loop_ct = 0\n",
    "\n",
    "#     for i, key in enumerate(keys):\n",
    "#         loop_ct += 1\n",
    "#         is_final_key = (i == len(keys) - 1)\n",
    "\n",
    "#         if isinstance(data, dict) and key in data:\n",
    "#             temp_data = data[key]\n",
    "#             if isinstance(temp_data, str):  # Found a string ID\n",
    "#                 id_ = temp_data\n",
    "#                 if not return_full:\n",
    "#                     return id_  # Return just the ID if return_full is False\n",
    "#                 return {\"id\": id_, \"all_keys\": data}\n",
    "#             data = data[key]\n",
    "\n",
    "#         elif isinstance(data, list):\n",
    "#             if len(data) > 0:\n",
    "#                 if is_final_key:\n",
    "#                     id_list = []\n",
    "#                     for data_dict in data:\n",
    "#                         if key in data_dict:\n",
    "#                             id_ = data_dict[key]\n",
    "#                             if not return_full:\n",
    "#                                 id_list.append(id_)  # Append just the ID if return_full is False\n",
    "#                                 continue\n",
    "#                             id_list.append({\"id\": id_, \"all_keys\": data_dict})\n",
    "#                         else:\n",
    "#                             return None  # Key not found\n",
    "#                     return id_list\n",
    "#             else:\n",
    "#                 print(\"Empty list encountered.\")\n",
    "#                 return None\n",
    "\n",
    "#         elif isinstance(data, str):\n",
    "#             if is_final_key and isinstance(temp_data, dict) and key in temp_data:\n",
    "#                 id_ = data\n",
    "#                 if not return_full:\n",
    "#                     return id_  # Return just the ID if return_full is False\n",
    "#                 return {\"id\": id_, \"all_keys\": temp_data}\n",
    "#             return {\"id\": data, \"all_keys\": temp_data}\n",
    "\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_biothings_apis(node_mappings, edge_mappings, client):\n",
    "#     ct=0\n",
    "#     # https://biothings.ci.transltr.io/rare_source/gene/100\n",
    "#     for biothings_api_data in tqdm(client.query(q=\"__all__\", fetch_all=True)):\n",
    "#         extract_biothings_nodes(node_mappings, biothings_api_data)\n",
    "#         extract_biothings_edges(edge_mappings, node_mappings, biothings_api_data) \n",
    "#         ct+=1\n",
    "#         if ct >= 1:\n",
    "#             break\n",
    "#     print(f\"📊 [INFO] Extracted {ct} records from BioThings API.\")\n",
    "\n",
    "# def extract_biothings_apis(node_mappings, edge_mappings, client):\n",
    "#     # Define the URL\n",
    "#     url = \"https://biothings.ci.transltr.io/rare_source/gene/100\"\n",
    "#     print(f\" 🔄[INFO] Extracting from URL: {url}\")\n",
    "#     # Make the GET request\n",
    "#     responseX = requests.get(url)\n",
    "#     # Check if the request was successful\n",
    "#     if responseX.status_code == 200:\n",
    "#         # Parse the JSON response\n",
    "#         biothings_api_data = responseX.json()\n",
    "#         extract_biothings_nodes(node_mappings, biothings_api_data)\n",
    "#         extract_biothings_edges(edge_mappings, node_mappings, biothings_api_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_biothings_nodes(node_mappings, biothings_api_data):\n",
    "#     # by data doc\n",
    "#     # print(api_data['entrezgene'])\n",
    "\n",
    "#     for node_uri, node_dict in node_mappings.items():\n",
    "#         key_identifier = node_dict[\"identifier\"]\n",
    "#         node_prefix = node_dict[\"prefix\"]\n",
    "#         # Change all instance to node_uri == node_cat\n",
    "#         # node_cat = node_uri #[key for key,value in node_mappings.items() if value['prefix'] == node_prefix] # why are we going through items here?\n",
    "#         node_api_data = get_nested_value(biothings_api_data, key_identifier)\n",
    "#         # pprint.pprint(node_api_data)\n",
    "#         node_uri = node_uri.split(\"-\")[1]  # Extract the URI part from the key\n",
    "#         # print(f\"[INFO] Node Typ: {node_uri} | Node ID: {key_identifier} | Prefix: {node_prefix}\")\n",
    "#         # print(f\"[INFO] Node category: {node_cat}\")\n",
    "#         # print(f\"[INFO] type: {type(node_ids)}\")\n",
    "\n",
    "#         # if node_api_data is None:\n",
    "#         #     continue\n",
    "#         if isinstance(node_api_data, dict):\n",
    "#             unique_node_id =  f\"{node_prefix}:{node_api_data['id']}\"\n",
    "#             name_key = node_dict[\"properties\"][\"name\"]\n",
    "#             unique_node_name = node_api_data[\"all_keys\"][f\"{name_key}\"]\n",
    "#             # print(f\"[INFO] Unique Node ID: {unique_node_id} | Unique Node Name: {unique_node_name}\")\n",
    "\n",
    "#             if unique_node_id not in nodes:\n",
    "#                 nodes[unique_node_id] = {\n",
    "#                     \"id\": unique_node_id,\n",
    "#                     \"name\": unique_node_name,\n",
    "#                     \"category\": [node_uri]\n",
    "#                     # \"provided_by\": [node_mappings[s_uri]['provided_by']]\n",
    "#                 }\n",
    "\n",
    "#                 for prop_key, prop_value in node_dict['properties'].items():\n",
    "#                     if \"cooccurrence_url\" == prop_key:\n",
    "#                         continue\n",
    "#                     elif \"orphanet\" == prop_key:\n",
    "#                         continue\n",
    "#                     if \".\" in prop_value and prop_key in node_api_data[\"all_keys\"]:\n",
    "#                         nodes[unique_node_id][prop_key] = node_api_data[\"all_keys\"][prop_key]\n",
    "#                     elif prop_key in  node_api_data[\"all_keys\"]:                                \n",
    "#                         nodes[unique_node_id][prop_key] = node_api_data[\"all_keys\"][prop_key]\n",
    "\n",
    "#         if isinstance(node_api_data, list):\n",
    "#             for id_ in node_api_data:\n",
    "#                 # unique_node_id =  f\"{node_prefix}:{id_['id']}\"\n",
    "#                 unique_node_name = id_[\"all_keys\"][\"name\"] \n",
    "\n",
    "#                 if unique_node_id not in nodes:\n",
    "#                     nodes[unique_node_id] = {\n",
    "#                         \"id\": unique_node_id,\n",
    "#                         \"name\": unique_node_name,\n",
    "#                         \"category\": [node_uri],\n",
    "#                     }\n",
    "\n",
    "#                     for prop_key, prop_value in node_dict['properties'].items():\n",
    "#                         if \"cooccurrence_url\" == prop_key:\n",
    "#                             continue\n",
    "#                         elif \"orphanet\" == prop_key:\n",
    "#                             continue\n",
    "#                         elif \".\" in prop_value and prop_key in id_[\"all_keys\"]:\n",
    "#                             nodes[unique_node_id][prop_key] = id_[\"all_keys\"][prop_key]\n",
    "\n",
    "#                         elif prop_key in  id_:                                \n",
    "#                             nodes[unique_node_id][prop_key] = id_[\"all_keys\"][prop_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_biothings_edges(edge_mappings, node_mappings, biothings_api_data): # no edge relations\n",
    "#     for p_uri, edge_map in edge_mappings.items():\n",
    "#         p_uri = p_uri.split(\"-\")[1]  # Extract the URI part from the key\n",
    "#         s_uri = edge_map[\"subject\"]\n",
    "#         sub_key_nodes = [node for node, value in node_mappings.items() if s_uri in node ]\n",
    "#         for node_key in sub_key_nodes:\n",
    "#             s_node_map = node_mappings[node_key]\n",
    "#             s_api_data = get_nested_value(biothings_api_data, s_node_map[\"identifier\"])\n",
    "#             if isinstance(s_api_data, dict): # should only be one subject? no list returned?\n",
    "#                 s_id = s_api_data[\"id\"]\n",
    "#                 s_id = f\"{s_node_map['prefix']}:{s_id}\"\n",
    "\n",
    "#             o_uri = edge_map[\"object\"]\n",
    "#             obj_key_nodes = [node for node, value in node_mappings.items() if o_uri in node ]\n",
    "#             for o_node_key in obj_key_nodes:\n",
    "#                 o_node_map = node_mappings[o_node_key]\n",
    "#                 o_api_data = get_nested_value(biothings_api_data, o_node_map[\"identifier\"])\n",
    "\n",
    "#                 # ref_url_dict = get_nested_value(biothings_api_data, edge_map['ref_url'])\n",
    "#                 # ref_url_path = edge_map['ref_url'].split(\".\")[-1]\n",
    "\n",
    "#                 if not isinstance(o_api_data, list):\n",
    "#                     o_api_data = [o_api_data]\n",
    "\n",
    "#                 for n in o_api_data:\n",
    "#                     if n is None:\n",
    "#                         # logger.info\n",
    "#                         # print(f\"Subject node, {s_id}, does not have an object node, {n}, api_data: {biothing_api_data}\")\n",
    "#                         continue\n",
    "#                     o_id = n[\"id\"]\n",
    "#                     o_id = f\"{o_node_map['prefix']}:{o_id}\"\n",
    "#                     rel = f\"{s_id}-{p_uri}-{o_id}\"\n",
    "#                     # process properties , merge key and value to edges \n",
    "#                     edges[rel] = {\n",
    "#                         \"subject\": s_id,\n",
    "#                         \"predicate\": p_uri.split(\":\")[-1],\n",
    "#                         \"object\": o_id,\n",
    "#                         \"knowledge_level\": edge_map['knowledge_level'],\n",
    "#                         \"agent_type\": edge_map['agent_type'],\n",
    "#                         \"primary_knowledge_source\": edge_map['primary_knowledge_source'],\n",
    "#                         # \"publications\": [n[\"all_keys\"][ref_url_path]] # assuming ref_url path alway in the object path\n",
    "#                     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "********************** Current Code **********************  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmt import Toolkit\n",
    "import requests\n",
    "import pprint\n",
    "import biothings_client\n",
    "import json\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize Biolink Model Toolkit\n",
    "BMT = Toolkit() # only want to initialize once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_value(data, key_path, return_full=True):\n",
    "    \"\"\"\n",
    "    Retrieve a value from a nested dictionary using a dot-separated key path.\n",
    "    Handles lists during traversal and can return just the ID or a full structure.\n",
    "\n",
    "    Example:\n",
    "        key_path = \"raresource.disease.orphanet\"\n",
    "        will return the value of data[\"raresource\"][\"disease\"][i][\"orphanet\"] if \"disease\" is a list.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The input dictionary to search.\n",
    "        key_path (str): Dot-separated key path (e.g., \"a.b.c\").\n",
    "        return_full (bool): If True, return {'id': ..., 'all_keys': ...}, else return just 'id'.\n",
    "\n",
    "    Returns:\n",
    "        str, dict, or list: Value(s) at the path, in requested format.\n",
    "    \"\"\"\n",
    "    def format_output(value, context):\n",
    "        return {\"id\": value, \"all_keys\": context} if return_full else value\n",
    "\n",
    "    keys = key_path.split(\".\")\n",
    "    current = data\n",
    "\n",
    "    for i, key in enumerate(keys):\n",
    "        is_last = (i == len(keys) - 1)\n",
    "\n",
    "        if isinstance(current, dict):\n",
    "            if key not in current:\n",
    "                return None\n",
    "            current = current[key]\n",
    "\n",
    "        elif isinstance(current, list):\n",
    "            results = []\n",
    "            for item in current:\n",
    "                if isinstance(item, dict) and key in item:\n",
    "                    val = item[key]\n",
    "                    results.append(format_output(val, item))\n",
    "            return results if results else None\n",
    "\n",
    "        else:\n",
    "            # If we hit a string, int, or unexpected type mid-path\n",
    "            return format_output(current, data)\n",
    "\n",
    "    return format_output(current, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_biolink_data_maps(data):\n",
    "    \"\"\"\n",
    "    Create Biolink Model-compliant node and edge mappings from MetaKG SmartAPI metadata.\n",
    "    \"\"\"\n",
    "    node_mappings = {}\n",
    "    edge_mappings = {}\n",
    "\n",
    "    for hit_doc in data.get(\"hits\", {}).get(\"hits\", []):\n",
    "        hit = hit_doc[\"_source\"]\n",
    "        api_info = hit[\"api\"]\n",
    "        bte_info = api_info.get(\"bte\", {})\n",
    "        query_op = bte_info.get(\"query_operation\", {})\n",
    "        response_mapping = bte_info.get(\"response_mapping\", {})\n",
    "\n",
    "        # Extract subject and object details\n",
    "        subj_cls = hit[\"subject\"]\n",
    "        subj_prefix = hit[\"subject_prefix\"]\n",
    "        subj_uri = BMT.get_element(subj_cls)[\"class_uri\"]\n",
    "        subj_id_path = query_op.get(\"request_body\", {}).get(\"body\", {}).get(\"scopes\")\n",
    "\n",
    "        obj_cls = hit[\"object\"]\n",
    "        obj_prefix = hit[\"object_prefix\"]\n",
    "        obj_uri = BMT.get_element(obj_cls)[\"class_uri\"]\n",
    "        obj_fields = query_op.get(\"params\", {}).get(\"fields\", \"\")\n",
    "        obj_fields = [f.strip() for f in obj_fields.split(\",\")]\n",
    "\n",
    "        # Predicate\n",
    "        predicate = hit[\"predicate\"]\n",
    "        pred_uri = BMT.get_element(predicate)[\"slot_uri\"] if BMT.get_element(predicate) else None\n",
    "\n",
    "        # Edge metadata\n",
    "        edge_rel = f\"{subj_uri}-{pred_uri}-{obj_uri}\"\n",
    "        provided_by = api_info.get(\"provided_by\")\n",
    "        agent_type = query_op.get(\"agent_type\")\n",
    "        knowledge_level = query_op.get(\"knowledge_level\")\n",
    "\n",
    "        # ------------------------\n",
    "        # EDGE MAPPING\n",
    "        # ------------------------\n",
    "        if pred_uri and BMT.is_translator_canonical_predicate(pred_uri):\n",
    "            if edge_rel not in edge_mappings:\n",
    "                edge_mappings[edge_rel] = {\n",
    "                    \"subject\": subj_uri,\n",
    "                    \"object\": obj_uri,\n",
    "                    \"primary_knowledge_source\": provided_by,\n",
    "                    \"agent_type\": agent_type,\n",
    "                    \"knowledge_level\": knowledge_level,\n",
    "                    \"properties\": {}\n",
    "                }\n",
    "\n",
    "            for predicate_key, mapping_dict in response_mapping.items():\n",
    "                if isinstance(mapping_dict, dict):\n",
    "                    for key, path in mapping_dict.items():\n",
    "                        if key == \"ref_url\":\n",
    "                            edge_mappings[edge_rel][\"properties\"][\"publications\"] = path\n",
    "\n",
    "        # ------------------------\n",
    "        # NODE MAPPINGS\n",
    "        # ------------------------\n",
    "        _add_node_mapping(\n",
    "            node_mappings,\n",
    "            prefix=subj_prefix,\n",
    "            uri=subj_uri,\n",
    "            identifier=subj_id_path,\n",
    "            is_subject=True\n",
    "        )\n",
    "\n",
    "        obj_id_path = extract_object_id_path(response_mapping, obj_prefix)\n",
    "\n",
    "        _add_node_mapping(\n",
    "            node_mappings,\n",
    "            prefix=obj_prefix,\n",
    "            uri=obj_uri,\n",
    "            identifier=obj_id_path,\n",
    "            is_subject=False,\n",
    "            extra_properties=collect_object_properties(response_mapping, obj_prefix)\n",
    "        )\n",
    "\n",
    "    return node_mappings, edge_mappings\n",
    "\n",
    "\n",
    "def _add_node_mapping(node_mappings, prefix, uri, identifier=None, is_subject=True, extra_properties=None):\n",
    "    rel_key = f\"{uri}\"\n",
    "    if rel_key not in node_mappings:\n",
    "        temp_dict = {\"prefix\": prefix, \"path\": identifier}\n",
    "        node_mappings[rel_key] = {\n",
    "            \"identifiers\": [temp_dict],\n",
    "            \"properties\": extra_properties or {}\n",
    "        }\n",
    "    else:\n",
    "        # Append prefix, identifier, and path if not already present\n",
    "        existing_identifiers = node_mappings[rel_key][\"identifiers\"]\n",
    "        new_identifier = {\"prefix\": prefix, \"path\": identifier}\n",
    "        \n",
    "        # Check if the new identifier already exists\n",
    "        if not any(\n",
    "            iden[\"prefix\"] == new_identifier[\"prefix\"] and iden[\"path\"] == new_identifier[\"path\"]\n",
    "            for iden in existing_identifiers\n",
    "        ):\n",
    "            node_mappings[rel_key][\"identifiers\"].append(new_identifier)\n",
    "        # Merge additional properties\n",
    "        if extra_properties:\n",
    "            node_mappings[rel_key][\"properties\"].update(extra_properties)\n",
    "\n",
    "\n",
    "def extract_object_id_path(response_mapping, object_prefix):\n",
    "    for _, mapping_dict in response_mapping.items():\n",
    "        if isinstance(mapping_dict, dict):\n",
    "            for key, path in mapping_dict.items():\n",
    "                if object_prefix.lower() in key.lower():  # Match \"umls\" in \"UMLS\"\n",
    "                    return path\n",
    "    return None\n",
    "\n",
    "\n",
    "def collect_object_properties(response_mapping, object_prefix):\n",
    "    properties = {}\n",
    "    for _, mapping_dict in response_mapping.items():\n",
    "        if isinstance(mapping_dict, dict):\n",
    "            for k, v in mapping_dict.items():\n",
    "                if k.lower() != \"ref_url\" and object_prefix.lower() not in k.lower():\n",
    "                    properties[k] = v\n",
    "    return properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_biothings_nodes(node_mappings, biothings_api_data):\n",
    "    \"\"\"\n",
    "    Enrich Biolink node mappings with BioThings API data and create structured node outputs.\n",
    "    \"\"\"\n",
    "    for node_uri, node_info in node_mappings.items():\n",
    "        for unique_node in node_info[\"identifiers\"]:\n",
    "            node_prefix = unique_node[\"prefix\"]\n",
    "            node_identifier = unique_node[\"path\"]\n",
    "\n",
    "            api_data = get_nested_value(biothings_api_data, node_identifier)\n",
    "            if not api_data:\n",
    "                continue\n",
    "\n",
    "            if isinstance(api_data, dict):\n",
    "                _process_single_node(api_data, node_prefix, node_uri, node_info)\n",
    "            elif isinstance(api_data, list):\n",
    "                for entry in api_data:\n",
    "                    _process_single_node(entry, node_prefix, node_uri, node_info)\n",
    "\n",
    "def _process_single_node(api_data, prefix, uri, node_info):\n",
    "    \"\"\"\n",
    "    Create or enrich a node from API data.\n",
    "    \"\"\"\n",
    "    node_id = f\"{prefix}:{api_data['id']}\"\n",
    "    name_key = node_info[\"properties\"].get(\"name\")\n",
    "    node_name = api_data[\"all_keys\"].get(name_key)\n",
    "\n",
    "    if node_id in nodes:\n",
    "        return  # Skip if already processed\n",
    "\n",
    "    nodes[node_id] = {\n",
    "        \"id\": node_id,\n",
    "        \"name\": node_name,\n",
    "        \"category\": [uri]\n",
    "    }\n",
    "\n",
    "    for prop_key, prop_val in node_info[\"properties\"].items():\n",
    "        if prop_key in {\"cooccurrence_url\", \"orphanet\"}:\n",
    "            continue\n",
    "\n",
    "        if \".\" in str(prop_val):\n",
    "            value = api_data[\"all_keys\"].get(prop_key)\n",
    "        else:\n",
    "            value = api_data[\"all_keys\"].get(prop_key)\n",
    "\n",
    "        if value is not None:\n",
    "            nodes[node_id][prop_key] = value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_biothings_edges(edge_mappings, node_mappings, biothings_api_data):\n",
    "    def format_node_id(node_map, api_data):\n",
    "        \"\"\"Helper to format node ID as prefix:id.\"\"\"\n",
    "        return f\"{node_map['prefix']}:{api_data['id']}\"\n",
    "\n",
    "    for edge_key, edge_map in edge_mappings.items():\n",
    "        predicate_uri = edge_key.split(\"-\")[1]  # Extract predicate URI part\n",
    "\n",
    "        # Find subject node keys containing subject URI\n",
    "        subject_nodes = [node for node in node_mappings if edge_map[\"subject\"] in node]\n",
    "        for s_node_key in subject_nodes:\n",
    "            s_node_map = node_mappings[s_node_key]\n",
    "            for s_unique_node in s_node_map[\"identifiers\"]:\n",
    "                s_api_data = get_nested_value(biothings_api_data, s_unique_node[\"path\"])\n",
    "                if not isinstance(s_api_data, dict) or s_api_data is None:\n",
    "                    continue  # Skip if no valid subject data\n",
    "\n",
    "                s_id = format_node_id(s_unique_node, s_api_data)\n",
    "\n",
    "                # Find object node keys containing object URI\n",
    "                object_nodes = [node for node in node_mappings if edge_map[\"object\"] in node]\n",
    "                for o_node_key in object_nodes:\n",
    "                    o_node_map = node_mappings[o_node_key]\n",
    "                    for o_unique_node in o_node_map[\"identifiers\"]:\n",
    "                        o_api_data = get_nested_value(biothings_api_data, o_unique_node[\"path\"])\n",
    "                        if o_api_data is None:\n",
    "                            continue\n",
    "                        if not isinstance(o_api_data, list):\n",
    "                            o_api_data = [o_api_data]\n",
    "\n",
    "                        for obj in o_api_data:\n",
    "                            if obj is None:\n",
    "                                continue\n",
    "                            o_id = format_node_id(o_unique_node, obj)\n",
    "\n",
    "                            rel = f\"{s_id}-{predicate_uri}-{o_id}\"\n",
    "                            edges[rel] = {\n",
    "                                \"subject\": s_id,\n",
    "                                \"predicate\": predicate_uri.split(\":\")[-1],\n",
    "                                \"object\": o_id,\n",
    "                                \"knowledge_level\": edge_map.get('knowledge_level'),\n",
    "                                \"agent_type\": edge_map.get('agent_type'),\n",
    "                                \"primary_knowledge_source\": edge_map.get('primary_knowledge_source'),\n",
    "                            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_kgx_dict(nodes, edges):\n",
    "    kgx_dict = {\n",
    "        \"nodes\": list(nodes.values()),\n",
    "        \"edges\": list(edges.values())\n",
    "    }\n",
    "    return kgx_dict\n",
    "\n",
    "# def get_nodes_and_edges(node_mappings, edge_mappings,client):\n",
    "#     nodes,edges = get_biothings_api(node_mappings, client, edge_mappings)\n",
    "#     return nodes, edges\n",
    "\n",
    "# # def remove_duplicates(list_of_dicts):\n",
    "# #     Remove duplicate dictionaries from a list of dictionaries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_biothings_apis(node_mappings, edge_mappings, client=None, size=1):\n",
    "    if size == 1 or client is None:\n",
    "        # Fallback to a single hardcoded example\n",
    "        url = \"https://biothings.ci.transltr.io/rare_source/gene/100\"\n",
    "        print(f\"🔗 [INFO] Extracting from URL: {url}\")\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            biothings_api_data = response.json()\n",
    "            extract_biothings_nodes(node_mappings, biothings_api_data)\n",
    "            extract_biothings_edges(edge_mappings, node_mappings, biothings_api_data)\n",
    "            print(f\"📊 [INFO] Extracted 1 record from BioThings API.\")\n",
    "        else:\n",
    "            print(f\"❌ [ERROR] Failed to fetch data from {url} (status: {response.status_code})\")\n",
    "    else:\n",
    "        print(f\"🔄 [INFO] Extracting up to {size} records using BioThings client...\")\n",
    "        count = 0\n",
    "        for biothings_api_data in tqdm(client.query(q=\"__all__\", fetch_all=True)):\n",
    "            extract_biothings_nodes(node_mappings, biothings_api_data)\n",
    "            extract_biothings_edges(edge_mappings, node_mappings, biothings_api_data)\n",
    "            count += 1\n",
    "            if count >= size:\n",
    "                break\n",
    "        print(f\"📊 [INFO] Extracted {count} records from BioThings API using client.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# batch_size = 1000  # or whatever works best\n",
    "# query_results = client.query(q=\"__all__\", scroll=True, size=batch_size)\n",
    "# for batch in tqdm(query_results):\n",
    "#     extract_biothings_nodes(node_mappings, batch)\n",
    "#     extract_biothings_edges(edge_mappings, node_mappings, batch)\n",
    "#     count += len(batch)\n",
    "#     if count >= size:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_kgx_to_json(kgx_data, output_file):\n",
    "    # Write the dictionary to a JSON file\n",
    "    with open(output_file, \"w\") as json_file:\n",
    "        json.dump(kgx_data, json_file, indent=4)  # Use indent for pretty formatting\n",
    "    print(f\"\\n📝 [INFO] KGX data written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_kgx_to_jsonl(kgx_data, nodes_jsonl_file, edges_jsonl_file):\n",
    "    # Write nodes to JSONL\n",
    "    with open(nodes_jsonl_file, \"w\") as nodes_file:\n",
    "        for node in kgx_data[\"nodes\"]:\n",
    "            json_str = json.dumps(node)\n",
    "            nodes_file.write(json_str + \"\\n\")\n",
    "            # json_str = json.dumps(node, separators=(', ', ': '))\n",
    "            # json_str = json_str.replace('{', '{ ', 1)  # add space after first '{'\n",
    "            # nodes_file.write(json_str + \"\\n\")\n",
    "\n",
    "    # Write edges to JSONL\n",
    "    with open(edges_jsonl_file, \"w\") as edges_file:\n",
    "        for edge in kgx_data[\"edges\"]:\n",
    "            json_str = json.dumps(edge)\n",
    "            edges_file.write(json_str + \"\\n\")\n",
    "            # json_str = json.dumps(edge, separators=(', ', ': '))\n",
    "            # json_str = json_str.replace('{', '{ ', 1)  # add space after first '{'\n",
    "            # edges_file.write(json_str + \"\\n\")\n",
    "\n",
    "    print(f\"📝 [INFO] KGx nodes written to {nodes_jsonl_file}\")\n",
    "    print(f\"📝 [INFO] KGx edges written to {edges_jsonl_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def run_kgx_pipeline(client, smartapi_url, debug=False, doc_size=10000):\n",
    "    print(\"🚀 [INFO] Starting KGx conversion pipeline...\")\n",
    "\n",
    "    # === Initialization ===\n",
    "    global nodes, edges\n",
    "    nodes = {}\n",
    "    edges = {}\n",
    "\n",
    "    # === Get smartapi metadata ===\n",
    "    print(f\"🔗 [INFO] Querying SmartAPI metadata: {smartapi_url}\")\n",
    "    # Send the request and retrieve data\n",
    "    response = requests.get(smartapi_url)\n",
    "    data = response.json()\n",
    "\n",
    "    # === Step 1: Create Biolink mappings from SmartAPI metadata ===\n",
    "    print(\"🛠️ [INFO] Creating Biolink mappings...\")\n",
    "    node_mappings, edge_mappings = make_biolink_data_maps(data)\n",
    "\n",
    "    # === Step 1.1: Add hardcoded property mappings for Disease and Gene ===\n",
    "    disease_dict = {\n",
    "        \"omim\": \"raresource.disease.omim\",\n",
    "        \"orphanet\": \"raresource.disease.orphanet\",\n",
    "        \"gard\": \"raresource.disease.gard\",\n",
    "        \"umls\": \"raresource.disease.umls\",\n",
    "        \"mesh\": \"raresource.disease.mesh\",\n",
    "        \"name\": \"raresource.disease.name\",\n",
    "        \"icd10cm\": \"raresource.disease.icd10cm\"\n",
    "    }\n",
    "\n",
    "    gene_dict = {\n",
    "        \"hgnc\": \"hgnc\",\n",
    "        # \"name\": \"name\",\n",
    "        \"ensemblgene\": \"ensemblgene\",\n",
    "        \"symbol\": \"symbol\",\n",
    "        \"name\": \"description\"\n",
    "    }\n",
    "\n",
    "    for s_uri, mapping in node_mappings.items():\n",
    "        props = mapping.get(\"properties\", {})\n",
    "        if \"Disease\" in s_uri:\n",
    "            for key, val in disease_dict.items():\n",
    "                props.setdefault(key, val)\n",
    "\n",
    "        if \"Gene\" in s_uri:\n",
    "            for key, val in gene_dict.items():\n",
    "                props.setdefault(key, val)\n",
    "\n",
    "            # Remove overly generic 'disease' field\n",
    "            props.pop(\"disease\", None)\n",
    "            mapping[\"properties\"] = props\n",
    "\n",
    "    print(\"\\n[DEBUG] Node Mappings:\")\n",
    "    pprint.pprint(node_mappings, indent=4)\n",
    "\n",
    "    print(\"\\n[DEBUG] Edge Mappings:\")\n",
    "    pprint.pprint(edge_mappings, indent=4)\n",
    "\n",
    "    # Write node mappings to a documentation file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"node_mappings_{timestamp}.txt\"\n",
    "\n",
    "    with open(output_filename, \"w\") as doc_file:\n",
    "        pprint.pprint(node_mappings, stream=doc_file, indent=4)\n",
    "        pprint.pprint(edge_mappings, stream=doc_file, indent=4)\n",
    "\n",
    "    print(f\"📝 [INFO] Node mappings written to {output_filename}\")\n",
    "\n",
    "    # # === Step 2: Extract nodes and edges using BioThings API ===\n",
    "    print(\"🔄 [INFO] Extracting nodes and edges from BioThings API...\")\n",
    "    extract_biothings_apis(node_mappings, edge_mappings, client, size=doc_size)\n",
    "    print(f\"📊 [INFO] Extracted {len(nodes)} nodes and {len(edges)} edges\")\n",
    "\n",
    "    # === Step 3: Format the graph as KGX-compatible dictionary ===\n",
    "    print(\"📦 [INFO] Formatting graph as KGX-compatible dictionary...\")\n",
    "    kgx_dict = format_kgx_dict(nodes, edges)\n",
    "    print(\"✅ [INFO] KGx dictionary formatted successfully.\")\n",
    "    return kgx_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- --- -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 [INFO] Starting KGx conversion pipeline...\n",
      "🔗 [INFO] Querying SmartAPI metadata: https://smart-api.info/api/metakg/?q=api.smartapi.id:b772ebfbfa536bba37764d7fddb11d6f&bte=1&meta=1&consolidated=0&size=100\n",
      "🛠️ [INFO] Creating Biolink mappings...\n",
      "\n",
      "[DEBUG] Node Mappings:\n",
      "{   'biolink:Disease': {   'identifiers': [   {   'path': 'raresource.disease.orphanet',\n",
      "                                                  'prefix': 'orphanet'},\n",
      "                                              {   'path': 'raresource.disease.umls',\n",
      "                                                  'prefix': 'UMLS'}],\n",
      "                           'properties': {   'gard': 'raresource.disease.gard',\n",
      "                                             'icd10cm': 'raresource.disease.icd10cm',\n",
      "                                             'mesh': 'raresource.disease.mesh',\n",
      "                                             'name': 'raresource.disease.name',\n",
      "                                             'omim': 'raresource.disease.omim',\n",
      "                                             'orphanet': 'raresource.disease.orphanet',\n",
      "                                             'umls': 'raresource.disease.umls'}},\n",
      "    'biolink:Gene': {   'identifiers': [   {   'path': 'entrezgene',\n",
      "                                               'prefix': 'NCBIGene'}],\n",
      "                        'properties': {   'ensemblgene': 'ensemblgene',\n",
      "                                          'hgnc': 'hgnc',\n",
      "                                          'name': 'description',\n",
      "                                          'output_name': 'symbol',\n",
      "                                          'symbol': 'symbol'}}}\n",
      "\n",
      "[DEBUG] Edge Mappings:\n",
      "{   'biolink:Gene-biolink:gene_associated_with_condition-biolink:Disease': {   'agent_type': 'manual_agent',\n",
      "                                                                               'knowledge_level': 'knowledge_assertion',\n",
      "                                                                               'object': 'biolink:Disease',\n",
      "                                                                               'primary_knowledge_source': 'infores:rare-source',\n",
      "                                                                               'properties': {   'publications': 'raresource.disease.cooccurrence_url'},\n",
      "                                                                               'subject': 'biolink:Gene'}}\n",
      "📝 [INFO] Node mappings written to node_mappings_20250618_141145.txt\n",
      "🔄 [INFO] Extracting nodes and edges from BioThings API...\n",
      "🔄 [INFO] Extracting up to 10000 records using BioThings client...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [00:01, 1270.75it/s]No more results to return.\n",
      "2901it [00:02, 1368.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 [INFO] Extracted 2901 records from BioThings API using client.\n",
      "📊 [INFO] Extracted 6638 nodes and 8155 edges\n",
      "📦 [INFO] Formatting graph as KGX-compatible dictionary...\n",
      "✅ [INFO] KGx dictionary formatted successfully.\n",
      "🟢 KGX pipeline executed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "api_name = \"rare_source\"\n",
    "api_id = \"b772ebfbfa536bba37764d7fddb11d6f\"\n",
    "bt_client = biothings_client.get_client(url=f\"https://biothings.ci.transltr.io/{api_name}\")\n",
    "smartapi_url = f\"https://smart-api.info/api/metakg/?q=api.smartapi.id:{api_id}&bte=1&meta=1&consolidated=0&size=100\"\n",
    "kgx_dict = run_kgx_pipeline(bt_client, smartapi_url, debug=True, doc_size=10000)\n",
    "if kgx_dict:\n",
    "    print(f\"🟢 KGX pipeline executed successfully.\")\n",
    "else:\n",
    "    print(f\"🔴 KGX pipeline execution failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 [INFO] KGX data written to raresource_kgx_new_map_full-doc_20250618.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and format it as YYYYMMDD\n",
    "current_datetime = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Add the date to the output filename\n",
    "output_filename = f\"raresource_kgx_new_map_full-doc_{current_datetime}.json\"\n",
    "\n",
    "# Write the KGX data to the JSON file\n",
    "write_kgx_to_json(kgx_dict, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 [INFO] KGx nodes written to raresource_nodes_1-doc_20250610.jsonl\n",
      "📝 [INFO] KGx edges written to raresource_edges_1-doc_20250610.jsonl\n"
     ]
    }
   ],
   "source": [
    "# nodes_jsonl_file = f\"raresource_nodes_1-doc_{current_datetime}.jsonl\"\n",
    "# edges_jsonl_file = f\"raresource_edges_1-doc_{current_datetime}.jsonl\"\n",
    "\n",
    "# write_kgx_to_jsonl(kgx_dict, nodes_jsonl_file, edges_jsonl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Validation -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_jsonl(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            try:\n",
    "                json.loads(line)  # Attempt to parse the line as JSON\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Invalid JSON on line {line_number}: {e}\")\n",
    "                return False\n",
    "    print(\"All lines are valid JSON.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_kgx_against_raw_and_metadata(kgx_data, original_data, smartapi_metadata):\n",
    "    errors = []\n",
    "    results = []\n",
    "\n",
    "    # --- Step 1: Validate node ---\n",
    "    expected_id = f\"NCBIGene:{original_data['entrezgene']}\"\n",
    "    node = next((n for n in kgx_data['nodes'] if n['id'] == expected_id), None)\n",
    "    \n",
    "    if not node:\n",
    "        errors.append(f\"Node for {expected_id} missing in KGX output.\")\n",
    "    else:\n",
    "        for field in ['name', 'symbol', 'hgnc', 'ensemblgene']:\n",
    "            if str(node.get(field)) != str(original_data.get(field)):\n",
    "                errors.append(f\"Node field mismatch for {field}: KGX has {node.get(field)}, original has {original_data.get(field)}\")\n",
    "\n",
    "    # --- Step 2: Build set of valid disease IDs from original ---\n",
    "    valid_disease_ids = set()\n",
    "    disease_list = original_data.get(\"raresource\", {}).get(\"disease\", [])\n",
    "\n",
    "    # Extract mapping prefixes from SmartAPI metadata\n",
    "    mapping_fields = {}\n",
    "    for hit in smartapi_metadata[\"hits\"][\"hits\"]:\n",
    "        mapping = hit[\"_source\"][\"api\"][\"bte\"].get(\"response_mapping\", {}).get(\"gene_associated_with_condition\", {})\n",
    "        for prefix, field_path in mapping.items():\n",
    "            mapping_fields[prefix.lower()] = field_path  # e.g., 'umls': 'raresource.disease.umls'\n",
    "\n",
    "    # Extract IDs using response_mapping\n",
    "    for disease in disease_list:\n",
    "        for prefix, field_path in mapping_fields.items():\n",
    "            parts = field_path.split(\".\")\n",
    "            value = disease\n",
    "            for key in parts[2:]:  # skip 'raresource.disease'\n",
    "                value = value.get(key) if isinstance(value, dict) else None\n",
    "            if value:\n",
    "                full_id = f\"{prefix}:{value}\"\n",
    "                valid_disease_ids.add(full_id)\n",
    "\n",
    "    # --- Step 3: Validate edges ---\n",
    "    for edge in kgx_data['edges']:\n",
    "        obj = edge.get('object')\n",
    "        subj = edge.get('subject')\n",
    "        pred = edge.get('predicate')\n",
    "\n",
    "        if obj not in valid_disease_ids:\n",
    "            errors.append(f\"Edge object ID {obj} not found in valid IDs extracted from original data.\")\n",
    "\n",
    "        if subj != expected_id:\n",
    "            errors.append(f\"Edge subject {subj} does not match expected gene ID {expected_id}\")\n",
    "\n",
    "        if pred != 'gene_associated_with_condition':\n",
    "            errors.append(f\"Unexpected predicate: {pred}\")\n",
    "\n",
    "        # Confirm source info\n",
    "        if edge.get(\"primary_knowledge_source\") != \"infores:rare-source\":\n",
    "            errors.append(f\"Incorrect knowledge source: {edge.get('primary_knowledge_source')}\")\n",
    "\n",
    "        results.append({\n",
    "            \"subject\": subj,\n",
    "            \"object\": obj,\n",
    "            \"valid\": obj in valid_disease_ids and subj == expected_id\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"valid_edges\": [r for r in results if r[\"valid\"]],\n",
    "        \"invalid_edges\": [r for r in results if not r[\"valid\"]],\n",
    "        \"errors\": errors\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = validate_kgx_against_raw_and_metadata(kgx_data, original_data, smartapi_metadata)\n",
    "# print(\"Errors:\")\n",
    "# for e in result['errors']:\n",
    "#     print(\" -\", e)\n",
    "\n",
    "# print(\"\\nValid edges:\", len(result['valid_edges']))\n",
    "# print(\"Invalid edges:\", len(result['invalid_edges']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All lines are valid JSON.\n",
      "All lines are valid JSON.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# # Example usage\n",
    "# edge_file_path = \"/Users/nacosta/Documents/Translator/KGx_conversion/raresource_edges_full_20250610.jsonl\"\n",
    "# validate_jsonl(edge_file_path)\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# node_file_path = \"/Users/nacosta/Documents/Translator/KGx_conversion/raresource_nodes_full_20250610.jsonl\"\n",
    "# validate_jsonl(edge_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KGX][jsonl_source.py][               parse] WARNING: Parse function cannot resolve the KGX file type in name raresource_nodes_full.jsonl. Skipped...\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# # def kgx_validate():\n",
    "# !kgx validate -i jsonl \"raresource_nodes_full.jsonl\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
